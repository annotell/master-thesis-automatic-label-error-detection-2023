{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import csv\n",
    "import time\n",
    "import pickle\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Manager, Process, Pool\n",
    "from functools import partial\n",
    "from itertools import compress, chain, repeat\n",
    "from operator import itemgetter\n",
    "import operator as op\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from skimage.draw import polygon_perimeter\n",
    "import matplotlib as mpl\n",
    "# matplotlib.use('TkAgg')\n",
    "import torch.nn.functional as F\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "\n",
    "import matplotlib.font_manager\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.stats import entropy, norm, uniform\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import faiss\n",
    "from cleanlab.classification import CleanLearning\n",
    "from cleanlab.filter import find_label_issues, find_predicted_neq_given, find_label_issues_using_argmax_confusion_matrix\n",
    "from cleanlab.dataset import health_summary\n",
    "from cleanlab.count import get_confident_thresholds, estimate_joint, compute_confident_joint, estimate_latent, estimate_noise_matrices, calibrate_confident_joint, estimate_py_and_noise_matrices_from_probabilities\n",
    "from cleanlab.rank import get_label_quality_scores, get_normalized_margin_for_each_label, get_self_confidence_for_each_label, get_confidence_weighted_entropy_for_each_label\n",
    "from cleanlab.internal.label_quality_utils import (\n",
    "    _subtract_confident_thresholds,\n",
    "    get_normalized_entropy,\n",
    ")\n",
    "\n",
    "from model import Net, GtsrbFolderWithPaths, SwedishFolderWithPaths\n",
    "\n",
    "\n",
    "from id_to_class import coco_shiftall_det as id2class\n",
    "from id_to_class import coco_shiftall_name2RGB as name2RGB\n",
    "from id_to_class import coco_shiftall_name2white as name2white\n",
    "from id_to_class import coco_shiftall_name2red as name2red\n",
    "\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# plt.rcParams['font.family'] = 'serif'\n",
    "# plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read SHIFT DataFrame (has true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######################################\n",
    "#                                  subset = shiftall\n",
    "######################################\n",
    "subset = 'shiftall'\n",
    "\n",
    "\n",
    "######################################\n",
    "#                                  subset = vehicle\n",
    "######################################\n",
    "# subset = 'vehicle'\n",
    "# shift_vehicle = {\n",
    "#     0: \"car\",\n",
    "#     1: \"truck\",\n",
    "#     2: \"bus\",\n",
    "#     # 3: \"pedestrian\",\n",
    "#     # 4: \"motorcycle\",\n",
    "#     # 5: \"bicycle\"\n",
    "# }\n",
    "# id2class = shift_vehicle\n",
    "\n",
    "######################################\n",
    "#                                  subset = moto\n",
    "######################################\n",
    "# subset = 'moto'\n",
    "# shift_moto = {\n",
    "#     0: \"pedestrian\",\n",
    "#     1: \"motorcycle\",\n",
    "#     2: \"bicycle\"\n",
    "#     # 3: \"car\",\n",
    "#     # 4: \"truck\",\n",
    "#     # 5: \"bus\",\n",
    "# }\n",
    "# id2class = shift_moto\n",
    "\n",
    "# shift_moto = {\n",
    "#     0: \"pedestrian\",\n",
    "#     1: \"motorcycle\",\n",
    "#     2: \"bicycle\"\n",
    "#     # 3: \"car\",\n",
    "#     # 4: \"truck\",\n",
    "#     # 5: \"bus\",\n",
    "# }\n",
    "\n",
    "# shift_moto_map = {\n",
    "#     0: 0, # original: pedestrian(0), new: pedestrian(0)\n",
    "#     4: 1, # original: motorcycle(4), new: motorcycle(1)\n",
    "#     5: 2, # original: bicycle(5), new: bicycle(2)\n",
    "#     1: 3, # original: car(1), new: car(3)\n",
    "#     2: 4, # original: truck(2), new: truck(4)\n",
    "#     3: 5  # original: bus(3), new: bus(5)\n",
    "# }\n",
    "\n",
    "m_names = ['uni20', 'uni10', 'uni5', 'uni1', 'ass20', 'ass10', 'ass5', 'ass1']\n",
    "# m_names = ['clean','uni20', 'uni10', 'uni5', 'uni1', 'ass20', 'ass10', 'ass5', 'ass1']\n",
    "\n",
    "\n",
    "# cog is slightly beter than ogc\n",
    "# coco_gdino_backbone = 'COCO_gdino_swint' # no coco pre-train\n",
    "coco_gdino_backbone = 'COCO_gdino_swinb' # with coco pre-train\n",
    "source_csv_dirpath = f'./postprocessing/code/DataFrame/{coco_gdino_backbone}'\n",
    "# source_csv_dirpath = d'./postprocessing/code/DataFrame/{coco_gdino_backbone}'\n",
    "tmp_figpath = './postprocessing/fig'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def convert_csv2np(df, colnames):\n",
    "\n",
    "    for col in colnames:\n",
    "        df[col] = df[col].apply(lambda x: np.asarray(x.split(';'), dtype=float))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_df_with_truelabels(csv_filepath, colnames):\n",
    "\n",
    "    \n",
    "    df = pd.read_csv(csv_filepath, header=0, delimiter=',', index_col=0)\n",
    "    df = convert_csv2np(df, colnames)\n",
    "    df = df.assign(c_incorrect=df['label_gt_des'] != df['true_label_des'])\n",
    "\n",
    "\n",
    "    for class_id, classname in id2class.items():\n",
    "        df[classname] = df['prob'].apply(lambda x: x[class_id])\n",
    "\n",
    "    return df\n",
    "\n",
    "# val_ass10_box0.2_all.csv  val_ass5_box0.2_all.csv   val_uni1_box0.2_all.csv\n",
    "# val_ass1_box0.2_all.csv   val_uni10_box0.2_all.csv  val_uni5_box0.2_all.csv\n",
    "\n",
    "colnames = ['bbox_gt', 'class_logit', 'class_logit_raw', 'prob', 'prob_sig']\n",
    "\n",
    "# m_dic = {m: None for m in m_names}\n",
    "rounds = list(range(1, 6))\n",
    "m_dic = {m: {int(r): None for r in rounds} for m in m_names}\n",
    "\n",
    "\n",
    "for _, m_name in tqdm(enumerate(m_names)):\n",
    "    for round_i in rounds:\n",
    "        source_csv_filepath = f'{source_csv_dirpath}/{m_name}/{subset}_{m_name}_round{round_i}.csv'\n",
    "        m_dic[m_name][int(round_i)] = read_df_with_truelabels(source_csv_filepath, colnames)\n",
    "        print(f'{source_csv_filepath} is loaded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix, roc_auc_score, precision_recall_fscore_support\n",
    "from scipy.special import softmax\n",
    "\n",
    "import math\n",
    "\n",
    "def cls_to_probs(cls_scores):\n",
    "\n",
    "    # print(f'[cls_to_probs] cls_score.shape={cls_score.shape}')\n",
    "\n",
    "    probs = softmax(cls_scores, axis=1)\n",
    "    # print('cls_score.shape=', cls_score.shape)\n",
    "    # print(f'scores.shape={probs.shape}')\n",
    "    # assert cls_scores.size(0) == gt_bboxes.size(0)\n",
    "\n",
    "    # sanity check\n",
    "    # close_to_1 = probs.sum(axis=1)\n",
    "    # print(f'close_to_1={close_to_1}')\n",
    "\n",
    "    return probs\n",
    "\n",
    "# csv_dirpath = './postprocessing/code/DataFrame/swedish'\n",
    "tmp_figpath = './postprocessing/fig'\n",
    "\n",
    "\n",
    "###############################################################\n",
    "#                 Number of Detected data                     #\n",
    "###############################################################\n",
    "# default_df = pd.read_csv(f'{csv_dirpath}/{default_csv_filename}', index_col=0, header=0)\n",
    "\n",
    "# is_issue_types = ['c_incorrect', 'c_correct', 'ambiguous']\n",
    "\n",
    "# All methods\n",
    "# methods = ['PBNR_NMargin','PBNR_SConf','PBNR_CWE','CL_NMargin','CL_SConf','CL_CWE','ArgMax_NMargin','ArgMax_SConf','ArgMax_CWE', 'LRank']\n",
    "\n",
    "# Selected methods\n",
    "# methods = ['PBNR_NMargin','PBNR_SConf', 'PBNR_CWE', 'LRank']\n",
    "\n",
    "# colnames = ['Epoch', 'Class',\n",
    "#             'TP', 'FP', 'TN', 'FN',\n",
    "#             'Precision', 'Recall', 'TNR']\n",
    "\n",
    "rounds = list(range(1, 6))\n",
    "colnames = ['round', 'model', 'classname', 'precision_ma', 'recall_ma', 'f1_ma', 'precision_mi', 'recall_mi', 'f1_mi']\n",
    "\n",
    "# if 6 in id2class.keys():\n",
    "#     del id2class[6]\n",
    "\n",
    "def gen_model_performance_df(m_names, m_dic, by_classes=False):\n",
    "    \n",
    "    dic = {m: None for m in m_names}\n",
    "\n",
    "    for m_name in m_names:\n",
    "        \n",
    "        print(f'-----------------Model {m_name} -----------------')\n",
    "\n",
    "        df = pd.DataFrame(columns=colnames)\n",
    "\n",
    "        for ri in rounds:\n",
    "            auc_values = []\n",
    "            # precision_macros, recall_macros, f1_macros = []\n",
    "            # precision_micros, recall_micros, f1_micros = []\n",
    "\n",
    "            # for epo in epos:\n",
    "            # print(f'Processing epoch {epo}')\n",
    "            epo_df = m_dic[m_name][ri]\n",
    "            \n",
    "            # don't need to remove the last element\n",
    "            # cls_score =np.stack(epo_df['cls_score'].to_numpy(), axis=0)\n",
    "            # remove the last element\n",
    "            # cls_score =np.stack(epo_df['cls_score'].to_numpy(), axis=0)[:,:-1]\n",
    "\n",
    "            # probs = cls_to_probs(cls_score)\n",
    "            probs =np.stack(epo_df['prob'].to_numpy(), axis=0)\n",
    "            # epo_df = epo_df.rename(columns={\"classname\": \"Class\"})\n",
    "\n",
    "            classnames = [i for i in id2class.values()]\n",
    "\n",
    "            if by_classes is False:\n",
    "\n",
    "                labels_gt_des = epo_df['label_gt_des'].tolist()\n",
    "                labels_pred_des = epo_df['label_pred_des'].tolist()\n",
    "\n",
    "                # (tn, fp, fn, tp) = confusion_matrix(labels_gt_des, labels_pred_des).ravel()\n",
    "                precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(labels_gt_des, labels_pred_des, average='macro')\n",
    "\n",
    "                precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(labels_gt_des, labels_pred_des, average='micro')\n",
    "\n",
    "                # precision_macros.append(precision_macro)\n",
    "                # recall_macros.append(recall_macro)\n",
    "                # f1_macros.append(f1_macro)\n",
    "                # precision_micros.append(precision_micro)\n",
    "                # recall_micros.append(recall_micro)\n",
    "                # f1_micros.append(f1_micro)\n",
    "\n",
    "\n",
    "                \n",
    "                # print(f'precision_macro={precision_macro}, recall_macro={recall_macro}, f1_macro={f1_macro}')\n",
    "                # print(f'precision_micro={precision_micro}, recall_micro={recall_micro}, f1_micro={f1_micro}')\n",
    "\n",
    "                assert precision_micro == recall_micro\n",
    "                # print('---')\n",
    "                # precision = 100.0 * tp / (tp+fp)\n",
    "                # recall = 100.0 * tp / (tp+fn)\n",
    "\n",
    "                classname = 'all'\n",
    "                row = [ri, m_name, classname, precision_macro, recall_macro, f1_macro, precision_micro, recall_micro, f1_micro]\n",
    "                df = pd.concat([df, pd.DataFrame([row], columns=colnames)], ignore_index=True)\n",
    "\n",
    "                # dic[m_name] = df\n",
    "                \n",
    "            # precision_macros_avg = np.average(precision_macros) * 100\n",
    "            # recall_macros_avg = np.average(recall_macros) * 100\n",
    "            # f1_macros_avg = np.average(f1_macros) * 100\n",
    "            # precision_macros_std = np.std(precision_macros) * 100\n",
    "            # recall_macros_std = np.std(recall_macros) * 100\n",
    "            # f1_macros_std = np.std(f1_macros) * 100\n",
    "\n",
    "\n",
    "                #     df = pd.concat([df, pd.DataFrame([row], columns=colnames)], ignore_index=True)\n",
    "                #     # print(f'-----------------End of Method {method}-----------------')\n",
    "                # else:\n",
    "\n",
    "                    # for classname in id2class.values():\n",
    "\n",
    "\n",
    "                    # class_df = epo_df.loc[epo_df['label_gt_des']==classname, :]\n",
    "\n",
    "            else:\n",
    "\n",
    "                class_df = epo_df.copy()\n",
    "\n",
    "                if len(class_df) == 0:\n",
    "                    print(f'No data for {classname} in round {ri}')\n",
    "        \n",
    "                labels_gt = class_df['label_gt'].to_numpy()\n",
    "                labels_gt_des = class_df['label_gt_des'].tolist()\n",
    "                labels_pred_des = class_df['label_pred_des'].tolist()\n",
    "\n",
    "                cm = multilabel_confusion_matrix(labels_gt_des, labels_pred_des, labels=classnames)\n",
    "\n",
    "                # auc_value = roc_auc_score(labels_gt, probs, multi_class='ovo', average='macro', labels=list(id2class.keys()))\n",
    "                # auc_values.append(auc_value)\n",
    "                # print(f'epoch={epo}, auc_value={auc_value}')\n",
    "\n",
    "                for idx, classname in enumerate(classnames):\n",
    "                    (tn, fp, fn, tp) = cm[idx].ravel()\n",
    "                    precision, recall, TNR = 0, 0, 0\n",
    "\n",
    "                    if tp+fp > 0:\n",
    "                        precision = 100.0 * tp / (tp + fp)\n",
    "\n",
    "                    if tp+fn > 0:\n",
    "                        recall = 100.0 * tp / (tp + fn)\n",
    "\n",
    "\n",
    "                    if tn + fp > 0:\n",
    "                        TNR = 100.0 * tn / (tn + fp)\n",
    "\n",
    "                    # TNR, true negative rate (TNR)\n",
    "                    row = [ri, classname, \n",
    "                            tp, fp, tn, fn,\n",
    "                            precision, recall, TNR]\n",
    "                    \n",
    "                    df = pd.concat([df, pd.DataFrame([row], columns=colnames)], ignore_index=True)\n",
    "\n",
    "            dic[m_name] = df\n",
    "\n",
    "        # auc_mean = np.average(auc_values) * 100\n",
    "        # auc_std = np.std(auc_values) * 100\n",
    "        # print(f'auc_mean={auc_mean}, auc_std={auc_std}, Latex={auc_mean:.2f} $\\pm$ {auc_std:.2f}')\n",
    "\n",
    "        print(f'-----------------End of {m_name}-----------------')\n",
    "\n",
    "    return dic\n",
    "\n",
    "m_names = [ 'uni20', 'uni10','uni5', 'uni1', 'ass20', 'ass10', 'ass5', 'ass1']\n",
    "# m_names = ['clean', 'uni20', 'uni10','uni5', 'uni1', 'ass20', 'ass10', 'ass5', 'ass1']\n",
    "\n",
    "perform_dic = gen_model_performance_df(m_names, m_dic, by_classes=False)\n",
    "perform_byclass_dic = gen_model_performance_df(m_names, m_dic, by_classes=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_macro_row = []\n",
    "recall_macro_row = []\n",
    "f1_macro_row = []\n",
    "precision_micro_row = []\n",
    "recall_micro_row = []\n",
    "f1_micro_row = []\n",
    "\n",
    "m_names = [ 'uni20', 'uni10', 'uni5', 'uni1', 'ass20', 'ass10', 'ass5', 'ass1']\n",
    "for m_name in m_names:\n",
    "    df = perform_dic[m_name].copy()\n",
    "    print(f'-----------------Model {m_name} -----------------')\n",
    "    precision_macro_str = f\"{100*df['precision_ma'].values.mean():.1f}$\\pm${100*df['precision_ma'].values.std():.1f}\"\n",
    "    precision_macro_row.append(precision_macro_str)\n",
    "    recall_macro_str = f\"{100*df['recall_ma'].values.mean():.1f}$\\pm${100*df['recall_ma'].values.std():.1f}\"\n",
    "    recall_macro_row.append(recall_macro_str)\n",
    "    f1_macro_str = f\"{100*df['f1_ma'].values.mean():.1f}$\\pm${100*df['f1_ma'].values.std():.1f}\"\n",
    "    f1_macro_row.append(f1_macro_str)\n",
    "\n",
    "    precision_micro_str = f\"{100*df['precision_mi'].values.mean():.1f}$\\pm${100*df['precision_mi'].values.std():.1f}\"\n",
    "    precision_micro_row.append(precision_micro_str)\n",
    "\n",
    "    recall_micro_str = f\"{100*df['recall_mi'].values.mean():.1f}$\\pm${100*df['recall_mi'].values.std():.1f}\"\n",
    "    recall_micro_row.append(recall_micro_str)\n",
    "    f1_micro_str = f\"{100*df['f1_mi'].values.mean():.1f}$\\pm${100*df['f1_mi'].values.std():.1f}\"\n",
    "    f1_micro_row.append(f1_micro_str)\n",
    "\n",
    "    print(f'Precision Micro: {precision_micro_str}')\n",
    "    print(f'Recall Micro: {recall_micro_str}')\n",
    "    print(f'F1 Micro: {f1_micro_str}')\n",
    "    print(f'')\n",
    "\n",
    "print(f'Micro Precision & {\" & \".join(precision_micro_row)}\\\\\\\\')\n",
    "print(f'Micro Recall & {\" & \".join(recall_micro_row)}\\\\\\\\')\n",
    "print(f'Micro F1 & {\" & \".join(f1_micro_row)} \\\\\\\\* \\midrule')\n",
    "\n",
    "print(f'Macro Precision & {\" & \".join(precision_macro_row)}\\\\\\\\')\n",
    "print(f'Macro Recall & {\" & \".join(recall_macro_row)}\\\\\\\\')\n",
    "print(f'Macro F1 & {\" & \".join(f1_macro_row)}\\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate AED Precsion Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "\n",
    "epos = list(range(1, 6))\n",
    "\n",
    "m_names = ['uni20', 'uni10', 'uni5', 'uni1', 'ass20', 'ass10', 'ass5', 'ass1']\n",
    "\n",
    "\n",
    "\n",
    "#################################\n",
    "#                 Number of Detected data                     #\n",
    "#################################\n",
    "# Selected methods\n",
    "methods = ['CL_SC', 'SC', 'LRank', 'CL_NM', 'NM']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cal_precision(df, detected_idxs, include_ambi, is_recall=False):\n",
    "\n",
    "    retrieved_elems = df.loc[detected_idxs, :]\n",
    "\n",
    "\n",
    "    if include_ambi is True:\n",
    "        TP_condition = (retrieved_elems['c_incorrect'] == True) | (retrieved_elems['ambiguous'] == True) \n",
    "    else:\n",
    "        TP_condition = (retrieved_elems['c_incorrect'] == True)\n",
    "\n",
    "    TP_df = retrieved_elems.loc[TP_condition]\n",
    "    FP_df = retrieved_elems.loc[(retrieved_elems['c_incorrect'] == False)]\n",
    "\n",
    "    if (len(TP_df)+len(FP_df)) == 0:\n",
    "        return 0, 0, 0, 0, 0\n",
    "\n",
    "    precision = 100.0 * len(TP_df) / (len(TP_df)+len(FP_df))\n",
    "\n",
    "    # print(f'detected_idxs={len(detected_idxs)}, TP={len(TP_df)}, FP={len(FP_df)}, Precision: {precision:.3f}%')\n",
    "    # assert (len(TP_df)+len(FP_df)) == len(detected_idxs)\n",
    "\n",
    "    recall = None\n",
    "    if is_recall:\n",
    "        relevant_elems = df.loc[df['c_incorrect']==True, :]\n",
    "\n",
    "        if len(relevant_elems) > 0:\n",
    "            recall = 100.0 * len(TP_df) / (len(relevant_elems))\n",
    "        else:\n",
    "            recall = 0.0\n",
    "        # FN_df = relevant_elems.loc[~relevant_elems.index.isin(detected_idxs), :]\n",
    "        # assert len(TP_df) + len(FP_df) + len(FN_df) == len(df)\n",
    "\n",
    "    TN_FP_condition = (df['c_incorrect'] == False)\n",
    "    TN_FP_df = df.loc[TN_FP_condition, :]\n",
    "    TN_df = TN_FP_df.loc[~TN_FP_df.index.isin(detected_idxs), :]\n",
    "\n",
    "    TNR = 100.0 *  len(TN_df) / len(TN_FP_df)\n",
    "\n",
    "    return len(TP_df), len(FP_df), precision, recall, TNR\n",
    "\n",
    "\n",
    "def gen_cal_df(m_names, methods, by_classes=False):\n",
    "    \n",
    "    cal_dic = {m: {epo:{method:{} for method in methods} for epo in epos} for m in m_names}\n",
    "    total_incorrects = {m: {} for m in m_names}\n",
    "\n",
    "    for m_name in m_names:\n",
    "        print(f'-----------------Model {m_name} -----------------')\n",
    "\n",
    "        # df_cal = pd.DataFrame(columns=colnames)\n",
    "\n",
    "        \n",
    "        for epo in epos:\n",
    "            # print(f'Processing epoch {epo}')\n",
    "\n",
    "            epo_df = m_dic[m_name][epo].copy()\n",
    "\n",
    "            # csv_filename = f'swe_{m_name}_epo{epo}.csv'\n",
    "            # epo_df = pd.read_csv(f'{csv_dirpath}/{m_name}/{csv_filename}', index_col=0, header=0)\n",
    "            # epo_df['prob'] = epo_df['prob'].apply(lambda x: np.asarray(x.split(';'), dtype=float))\n",
    "            \n",
    "            # accuracy for each method (without Lrank)\n",
    "            for method in methods:\n",
    "\n",
    "                top_percentage = 1.0\n",
    "                # print(f'Processing method {method}')\n",
    "\n",
    "                if by_classes is False:\n",
    "                    classname = 'all'\n",
    "                    total_incorrects[m_name].update({classname: len(epo_df.loc[epo_df['c_incorrect']==True])})\n",
    "                \n",
    "                    if method == 'LRank':\n",
    "                        # topn_thresh = int(round(len(epo_df.loc[epo_df['CL_SC'] != 999999]) * top_percentage))\n",
    "\n",
    "\n",
    "                        # print(f'topNthresh={topNthresh} for LRank')\n",
    "                        detected_df = epo_df.sort_values(by='loss', ascending=False)\n",
    "                        epo_df.sort_values(by='loss', ascending=False, inplace=True)\n",
    "                        # detected_df = lossrank_df[:topn_thresh]\n",
    "                        # detected_df = epo_df.loc[epo_df[method] <= topNthresh]\n",
    "                    \n",
    "                    elif method  in ['NM', 'SC', 'EN']:\n",
    "                        # cl_idxs = epo_df.loc[epo_df['CL_SC'] != 999999].index.values\n",
    "\n",
    "                        detected_df = epo_df.sort_values(by=method, ascending=True)\n",
    "                        epo_df.sort_values(by=method, ascending=True, inplace=True)\n",
    "\n",
    "                    elif method  in ['REN', 'RC']:\n",
    "                        # cl_idxs = epo_df.loc[epo_df['CL_SC'] != 999999].index.values\n",
    "\n",
    "                        # For entropy and relative entropy\n",
    "                        # higher the better\n",
    "                        detected_df = epo_df.sort_values(by=method, ascending=False)\n",
    "                        epo_df.sort_values(by=method, ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        detected_df = epo_df.loc[epo_df[method] != 999999].sort_values(by=method, ascending=True)\n",
    "                        epo_df.sort_values(by=method, ascending=True, inplace=True)\n",
    "\n",
    "                        # detected_df = epo_df.loc[epo_df[method] != 999999].sort_values(by=method, ascending=True)\n",
    "                        # topn = int(round(len(detected_df) * top_percentage))\n",
    "                        # detected_df = detected_df[:topn]\n",
    "\n",
    "\n",
    "                    detected_idxs = detected_df.index.tolist()\n",
    "\n",
    "                    # incorrects = epo_df.loc[detected_idxs, 'c_incorrect'].apply(lambda x: 'TP' if x is True else 'FP').values\n",
    "                    incorrects = epo_df['c_incorrect'].apply(lambda x: 'FN' if x is True else 'TN')\n",
    "                    true_labels_des = epo_df['true_label_des']\n",
    "                    labels_gt_des = epo_df['label_gt_des']\n",
    "                    labels_pred_des = epo_df['label_pred_des']\n",
    "                    incorrects_subset = incorrects[detected_idxs].apply(lambda x: 'TP' if x == 'FN' else 'FP')\n",
    "                    incorrects.update(incorrects_subset)\n",
    "\n",
    "\n",
    "                    # incorrects.loc[detected_idxs, 'c_incorrect'] = 'TP' if x == 'FN' else 'FP'\n",
    "\n",
    "                    cal_dic[m_name][epo][method].update({classname: incorrects})\n",
    "                    cal_dic[m_name][epo][method].update({'true_labels_des': true_labels_des})\n",
    "                    cal_dic[m_name][epo][method].update({'labels_gt_des': labels_gt_des})\n",
    "                    cal_dic[m_name][epo][method].update({'labels_pred_des': labels_pred_des})\n",
    "\n",
    "                else:\n",
    "\n",
    "                    for classname in id2class.values():\n",
    "\n",
    "                        class_df =epo_df.loc[epo_df['label_gt_des']==classname, :]\n",
    "\n",
    "                        total_incorrects[m_name].update({classname: len(class_df.loc[class_df['c_incorrect']==True])})\n",
    "                        # class_df =epo_df.loc[epo_df['label_gt_des']==classname, :]\n",
    "\n",
    "                        if len(class_df) == 0:\n",
    "                            print(f'No data for {classname} in epoch {epo}')\n",
    "                \n",
    "                        if method == 'LRank':\n",
    "                            # topn_thresh = int(round(len(class_df.loc[class_df['CL_SC'] != 999999]) * top_percentage))\n",
    "\n",
    "\n",
    "                            # print(f'topNthresh={topNthresh} for LRank')\n",
    "                            detected_df = class_df.sort_values(by='loss', ascending=False)\n",
    "                            class_df.sort_values(by='loss', ascending=False, inplace=True)\n",
    "\n",
    "                            # detected_df = lossrank_df[:topn_thresh]\n",
    "                            # detected_df = class_df.loc[class_df[method] <= topNthresh]\n",
    "                        \n",
    "                        elif method  in ['NM', 'SC', 'EN']:\n",
    "                            # cl_idxs = class_df.loc[class_df['CL_SC'] != 999999].index.values\n",
    "\n",
    "                            detected_df = class_df.sort_values(by=method, ascending=True)\n",
    "                            class_df.sort_values(by=method, ascending=True, inplace=True)\n",
    "\n",
    "\n",
    "                        elif method  in ['REN', 'RC']:\n",
    "                            # cl_idxs = class_df.loc[class_df['CL_SC'] != 999999].index.values\n",
    "\n",
    "                            detected_df = class_df.sort_values(by=method, ascending=False)\n",
    "                            class_df.sort_values(by=method, ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "                        else:\n",
    "                            detected_df = class_df.loc[class_df[method] != 999999].sort_values(by=method, ascending=True)\n",
    "                            class_df.sort_values(by=method, ascending=True, inplace=True)\n",
    "\n",
    "                            # topn = int(round(len(detected_df) * top_percentage))\n",
    "                            # detected_df = detected_df[:topn]\n",
    "\n",
    "\n",
    "                        detected_idxs = detected_df.index.tolist()\n",
    "\n",
    "                        # incorrects = class_df.loc[detected_idxs, 'c_incorrect'].apply(lambda x: 'TP' if x is True else 'FP').values\n",
    "                        # incorrects = class_df['c_incorrect'].apply(lambda x: 'FN' if x is True else 'TN')\n",
    "                        # incorrects = incorrects[detected_idxs].apply(lambda x: 'TP' if x == 'FN' else 'FP')\n",
    "                        incorrects = class_df['c_incorrect'].apply(lambda x: 'FN' if x is True else 'TN')\n",
    "                        incorrects_subset = incorrects[detected_idxs].apply(lambda x: 'TP' if x == 'FN' else 'FP')\n",
    "                        incorrects.update(incorrects_subset)\n",
    "\n",
    "                        cal_dic[m_name][epo][method].update({classname: incorrects})\n",
    "\n",
    "\n",
    "        # cal_dic[m_name] = df_cal\n",
    "\n",
    "        print(f'-----------------End of Epoch {epo}-----------------')\n",
    "\n",
    "    return cal_dic, total_incorrects\n",
    "\n",
    "topn_dic, total_incorrects = gen_cal_df(m_names, methods, by_classes=False)\n",
    "topn_byclass_dic, total_byclass_incorrects = gen_cal_df(m_names, methods, by_classes=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save pkl:  topn_dic and perform_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_pkl(obj, filepath):\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def read_pkl(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "aed_perf_dirpath = f'./postprocessing/code/DataFrame/{coco_gdino_backbone}/aed_topn'\n",
    "\n",
    "if not os.path.isdir(aed_perf_dirpath):\n",
    "    os.makedirs(aed_perf_dirpath, exist_ok=True)\n",
    "\n",
    "aed_perf_filename = f'aed_topn'\n",
    "aed_perf_filepath = f'{aed_perf_dirpath}/aed_topn.pkl'\n",
    "\n",
    "# perform_dic, perform_byclass_dic\n",
    "# topn_dic, total_incorrects\n",
    "# topn_byclass_dic, total_byclass_incorrects\n",
    "\n",
    "###########################\n",
    "#                            Save file\n",
    "# aed_topn_obj = {\n",
    "#     'all': topn_dic,\n",
    "#     'all_incorrect': total_incorrects,\n",
    "#     'byclass': topn_byclass_dic, \n",
    "#     'byclass_incorrect': total_byclass_incorrects,\n",
    "#     'perform_dic': perform_dic,\n",
    "#     'perform_byclass_dic': perform_byclass_dic\n",
    "# }\n",
    "# save_pkl(aed_topn_obj, aed_perf_filepath)\n",
    "# print(f'Saved to {aed_perf_filepath}')\n",
    "\n",
    "###########################\n",
    "#                          Read file\n",
    "aed_topn = read_pkl(aed_perf_filepath)\n",
    "\n",
    "topn_dic = aed_topn['all']\n",
    "total_incorrects = aed_topn['all_incorrect']\n",
    "topn_byclass_dic = aed_topn['byclass']\n",
    "total_byclass_incorrects = aed_topn['byclass_incorrect']\n",
    "perform_dic = aed_topn['perform_dic']\n",
    "perform_byclass_dic = aed_topn['perform_byclass_dic']\n",
    "\n",
    "print(f'Read aed_topn {aed_perf_filepath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show images / Save Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.draw import polygon_perimeter\n",
    "import cv2\n",
    "\n",
    "def draw_bboxes(img, gt_bboxes, gt_labels, gt_labels_des, pred_labels, pred_labels_des, name2RGB, name2white, isshow, isfont):\n",
    "\n",
    "    for idx, (gt_bbox, gt_label, gt_label_des, pred_label, pred_label_des) in enumerate(zip(gt_bboxes, gt_labels, gt_labels_des, pred_labels, pred_labels_des)):\n",
    "\n",
    "        ymin, xmin, ymax, xmax = [int(i) for i in gt_bbox]\n",
    "        \n",
    "        # start = (xmin, ymin)\n",
    "        # end = (xmax, ymax)\n",
    "        r = [xmin, xmax, xmax, xmin, xmin]\n",
    "        c = [ymax, ymax, ymin, ymin, ymax]\n",
    "        rr, cc = polygon_perimeter(r, c, img.shape)\n",
    "        # rr, cc = polygon_perimeter(start, end=end, shape=img.shape)\n",
    "        rgb = name2RGB[gt_label_des]\n",
    "        img[rr, cc ,0] = rgb[0]\n",
    "        img[rr, cc ,1] = rgb[1]\n",
    "        img[rr, cc ,2] = rgb[2]\n",
    "\n",
    "        if isfont is True:\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            text_org = (ymin, xmin-2)\n",
    "\n",
    "            if gt_label_des == 'traffic sign':\n",
    "                gt_label_des = 'sign'\n",
    "            elif gt_label_des == 'traffic light':\n",
    "                gt_label_des = 'light'\n",
    "\n",
    "            labeltext = f'{gt_label_des}'\n",
    "            cv2.putText(img, labeltext, text_org, font, 0.5, rgb, 1)\n",
    "\n",
    "    # print(f'img.shape={img.shape}')\n",
    "    # img = np.moveaxis(img, 0, -1)\n",
    "    \n",
    "    # dpi = 150\n",
    "    # fig = plt.figure(dpi=dpi, figsize=(12,14))\n",
    "    # plt.imshow(img)\n",
    "    if isshow is True:\n",
    "        dpi = 150\n",
    "        fig = plt.figure(dpi=dpi, figsize=(7,9))\n",
    "        plt.imshow(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def crop_bbox(xmin, ymin, xmax, ymax, img, img_shape, pad=0):\n",
    "    img_xmax = img_shape[0]\n",
    "    img_ymax = img_shape[1]\n",
    "    xmin = int(xmin) - pad if int(xmin) - pad > 0 else 0\n",
    "    ymin = int(ymin) - pad if int(ymin) - pad > 0 else 0\n",
    "    xmax = int(xmax) + pad if int(xmin) + pad > 0 else img_xmax\n",
    "    ymax = int(ymax) + pad if int(ymax) + pad > 0 else img_ymax\n",
    "\n",
    "    # print(f'img.shape={img.shape}')\n",
    "    cropped = img[xmin:xmax, ymin:ymax, :]\n",
    "    # print(f'cropped.shape={cropped.shape}')\n",
    "    return cropped\n",
    "    \n",
    "\n",
    "def crop_bboxes(img, img_shape, gt_bboxes, gt_labels, pad):\n",
    "    bbox_imgs = []\n",
    "\n",
    "    for idx, (bbox, labels) in enumerate(zip(gt_bboxes, gt_labels)):\n",
    "        ymin, xmin, ymax, xmax = bbox\n",
    "        \n",
    "        bbox_img = crop_bbox(xmin, ymin, xmax, ymax, img, img_shape, pad)\n",
    "        bbox_imgs.append(bbox_img)\n",
    "\n",
    "    return bbox_imgs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(id2class.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "m_names = ['uni20', 'ass20', 'uni10', 'ass10', 'uni5', 'ass5', 'uni1', 'ass1']\n",
    "m_name = 'ass10'\n",
    "epo = 1 # this is the round\n",
    "topn = 10\n",
    "ranked_by = 'NM'\n",
    "classname = 'all'\n",
    "# classname = 'truck'\n",
    "# classname = 'motorcycle'\n",
    "# colnames = [\"cls_score\", \"label_gt\", \"label_gt_des\", \"label_pred\", \"label_pred_des\", \"imgpath\", \"bbox_gt\",\"prob\", \"CL_SC\", \"SC\", \"loss\", \"CL_NM\", \"NM\"]\n",
    "\n",
    "epo_df = m_dic[m_name][epo].copy()\n",
    "if classname != 'all':\n",
    "    class_df = epo_df.loc[epo_df['label_gt_des']==classname]\n",
    "else:\n",
    "    class_df = epo_df\n",
    "\n",
    "# class_df = epo_df.loc[epo_df['label_gt_des']==classname]\n",
    "class_df.sort_values(by=ranked_by, ascending=True, inplace=True)\n",
    "class_df = class_df.head(topn)\n",
    "print_str = class_df['imgpath'].values\n",
    "print(print_str)\n",
    "\n",
    "classes = list(id2class.values())\n",
    "\n",
    "# print(f'{class_df[\"NM\"]}')\n",
    "\n",
    "# def draw_single_barplot(df, classes, yname, ylimit, colors, label_gt_des):\n",
    "#     plt.figure(figsize=(6, 4))\n",
    "#     colors = ['red' if cname == label_gt_des else 'gray' for cname in df['class']]\n",
    "#     g=sns.barplot(df, x=\"class\", y=\"nmnll\", palette=colors)\n",
    "#     labels_str = [f'{i:.2f}' for i in df['nmnll']]\n",
    "#     # labels_str[label_gt] = f'{nmnll[label_gt]:.2f}'\n",
    "#     for container in g.containers:\n",
    "#         g.bar_label(container, labels=labels_str, label_type='edge')\n",
    "#     ######################\n",
    "#     g.set_ylim([0, ylimit])\n",
    "#     g.tick_params(axis='y', labelsize=10)\n",
    "#     g.tick_params(axis='x', labelsize=10)\n",
    "#     plt.xticks(rotation=30, ha='center')\n",
    "#     g.set_xlabel(f'Anno={label_gt_des}', fontsize=14)\n",
    "#     g.set_ylabel(f'{yname}', fontsize=8)\n",
    "#     plt.show()\n",
    "\n",
    "def draw_multirow_single(topn, df, yaxis, classname, classes, fig_path):\n",
    "\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    class_df['maxprob'] = class_df['prob'].apply(lambda x: np.max(x))\n",
    "    class_df['probnll'] = class_df['prob'].apply(lambda x: -np.log(x))\n",
    "    class_df['maxprobnll'] = class_df['probnll'].apply(lambda x: np.max(x))\n",
    "\n",
    "    class_df['nm'] = class_df['prob'].apply(lambda x: cal_margin(x))\n",
    "    class_df['nmnll'] = class_df['nm'].apply(lambda x: -np.log(x))\n",
    "    class_df['maxnmnll'] = class_df['nmnll'].apply(lambda x: np.max(x))\n",
    "\n",
    "    ylimit = None\n",
    "\n",
    "\n",
    "    for rank_i in [8]:\n",
    "\n",
    "        item_df = class_df.iloc[rank_i]\n",
    "\n",
    "        true_label_des = item_df['true_label_des']\n",
    "        label_gt = item_df['label_gt']\n",
    "        label_gt_des = item_df['label_gt_des']\n",
    "        label_pred = item_df['label_pred']\n",
    "        label_pred_des = item_df['label_pred_des']\n",
    "\n",
    "        maxprob_i = item_df['maxprob']\n",
    "        maxprob_i2 = class_df['maxprob'].iloc[rank_i]\n",
    "        assert maxprob_i == maxprob_i2, f'maxprob_i={maxprob_i}, maxprob_i2={maxprob_i2}'\n",
    "\n",
    "        probnll = item_df['probnll']\n",
    "        maxprobnll = np.max(class_df['maxprobnll'])\n",
    "        maxprobnll_i = item_df['maxprobnll']\n",
    "        maxprobnll_i2 = class_df['maxprobnll'].iloc[rank_i]\n",
    "        assert maxprobnll_i == maxprobnll_i2, f'maxprobnll_i={maxprobnll_i}, maxprobnll_i2={maxprobnll_i2}'\n",
    "\n",
    "        nmnll = item_df['nmnll']\n",
    "        maxnmnll = np.max(class_df['maxnmnll'])\n",
    "        maxnmnll_i = item_df['maxnmnll']\n",
    "        maxnmnll_i2 = class_df['maxnmnll'].iloc[rank_i]\n",
    "        assert maxnmnll_i == maxnmnll_i2, f'maxnmnll_i={maxnmnll_i}, maxnmnll_i2={maxnmnll_i2}'\n",
    "\n",
    "        d = {'probnll': item_df['probnll'], 'prob': item_df['prob'], 'class': classes, 'nmnll': item_df['nmnll']}\n",
    "        df = pd.DataFrame(data=d)\n",
    "        colors = ['red' if cname == label_gt_des else 'gray' for cname in df['class']]\n",
    "\n",
    "        plt.figure(figsize=(6, 4))\n",
    "\n",
    "        if yaxis == 'Predictive Probability':\n",
    "            ylimit = 1\n",
    "            yname = yaxis\n",
    "            yshortname = 'prob'\n",
    "            labels_str = [f'{i:.3f}' for i in df['prob']]\n",
    "            g=sns.barplot(df, x=\"class\", y=\"prob\", palette=colors)\n",
    "            barfontsize = 9\n",
    "\n",
    "\n",
    "        elif yaxis == 'Self-Confidence':\n",
    "            ylimit = maxprobnll\n",
    "            yshortname = 'probnll'\n",
    "            yname = 'Negative Log of Self-Confidence'\n",
    "            labels_str = [f'{i:.2f}' for i in df['probnll']]\n",
    "            g=sns.barplot(df, x=\"class\", y=\"probnll\", palette=colors)\n",
    "            barfontsize = 11\n",
    "\n",
    "\n",
    "        elif yaxis == 'Normalized Margin':\n",
    "            ylimit = maxnmnll\n",
    "            yshortname = 'nmnll'\n",
    "            yname = 'Negative Log of Normalized Margin'\n",
    "            labels_str = [f'{i:.2f}' for i in df['nmnll']]\n",
    "            g=sns.barplot(df, x=\"class\", y=\"nmnll\", palette=colors)\n",
    "            barfontsize = 11\n",
    "\n",
    "        red_i = 5\n",
    "        for container in g.containers:\n",
    "            tboxes = g.bar_label(container, labels=labels_str, label_type='edge', fontsize=barfontsize)\n",
    "            tboxes[red_i].set_color('red')\n",
    "        ######################\n",
    "        g.set_ylim([0, ylimit])\n",
    "        g.tick_params(axis='y', labelsize=10)\n",
    "        g.tick_params(axis='x', labelsize=10)\n",
    "\n",
    "        plt.gca().get_xticklabels()[red_i].set_color(\"red\")\n",
    "        # plt.gca().get_xticklabels()[8].set_color(\"red\")\n",
    "        plt.xticks(rotation=40, ha='center')\n",
    "        g.set_xlabel(f'True={true_label_des}\\nAnno={label_gt_des}', fontsize=14)\n",
    "        g.set_ylabel(f'{yname}', fontsize=8)\n",
    "        plt.savefig(f'{fig_dirpath}/{rank_i}_{yshortname}.png', dpi=80)\n",
    "        print(f'Save to {fig_dirpath}/{rank_i}_{yshortname}.png')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "def find_max(array, value):\n",
    "    return np.max(array)\n",
    "\n",
    "def cal_margin(arr):\n",
    "    margins = []\n",
    "    for i, prob in enumerate(arr):\n",
    "\n",
    "        new_arr = np.delete(arr, i)\n",
    "        next_prob = find_max(new_arr, value=prob)\n",
    "        margin = ((prob - next_prob) +1)/2\n",
    "        margins.append(margin)\n",
    "    \n",
    "    # print(f'margins={margins}')\n",
    "    margins = np.absolute(margins)\n",
    "\n",
    "    return margins\n",
    "\n",
    "def draw_multirow(topn, df, yaxis, classname, classes, fig_path):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=topn, sharey=True, sharex=True, figsize=(16, 2))\n",
    "    # fig, axes = plt.subplots(nrows=1, ncols=topn, sharey=True, sharex=True, figsize=(16, 2), constrained_layout=True)\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    # fig.suptitle(f'{yaxis}', fontsize=12)\n",
    "\n",
    "\n",
    "    class_df['maxprob'] = class_df['prob'].apply(lambda x: np.max(x))\n",
    "    class_df['probnll'] = class_df['prob'].apply(lambda x: -np.log(x))\n",
    "    class_df['maxprobnll'] = class_df['probnll'].apply(lambda x: np.max(x))\n",
    "\n",
    "    class_df['nm'] = class_df['prob'].apply(lambda x: cal_margin(x))\n",
    "    class_df['nmnll'] = class_df['nm'].apply(lambda x: -np.log(x))\n",
    "    class_df['maxnmnll'] = class_df['nmnll'].apply(lambda x: np.max(x))\n",
    "\n",
    "    ylimit = None\n",
    "\n",
    "    for rank_i, ax in zip(range(0, topn), axes.flatten()):\n",
    "\n",
    "        item_df = class_df.iloc[rank_i]\n",
    "\n",
    "        true_label_des = item_df['true_label_des']\n",
    "        label_gt = item_df['label_gt']\n",
    "        label_gt_des = item_df['label_gt_des']\n",
    "        label_pred = item_df['label_pred']\n",
    "        label_pred_des = item_df['label_pred_des']\n",
    "\n",
    "        maxprob_i = item_df['maxprob']\n",
    "        maxprob_i2 = class_df['maxprob'].iloc[rank_i]\n",
    "        assert maxprob_i == maxprob_i2, f'maxprob_i={maxprob_i}, maxprob_i2={maxprob_i2}'\n",
    "\n",
    "        probnll = item_df['probnll']\n",
    "        maxprobnll = np.max(class_df['maxprobnll'])\n",
    "        maxprobnll_i = item_df['maxprobnll']\n",
    "        maxprobnll_i2 = class_df['maxprobnll'].iloc[rank_i]\n",
    "        assert maxprobnll_i == maxprobnll_i2, f'maxprobnll_i={maxprobnll_i}, maxprobnll_i2={maxprobnll_i2}'\n",
    "\n",
    "        nmnll = item_df['nmnll']\n",
    "        maxnmnll = np.max(class_df['maxnmnll'])\n",
    "        maxnmnll_i = item_df['maxnmnll']\n",
    "        maxnmnll_i2 = class_df['maxnmnll'].iloc[rank_i]\n",
    "        assert maxnmnll_i == maxnmnll_i2, f'maxnmnll_i={maxnmnll_i}, maxnmnll_i2={maxnmnll_i2}'\n",
    "\n",
    "        d = {'probnll': item_df['probnll'], 'prob': item_df['prob'], 'class': classes, 'nmnll': item_df['nmnll']}\n",
    "        df = pd.DataFrame(data=d)\n",
    "        colors = ['red' if cname == label_gt_des else 'gray' for cname in df['class']]\n",
    "\n",
    "        if yaxis == 'Predictive Probability':\n",
    "            ax.set_ylim([0, 1])\n",
    "            g1 = sns.barplot(df, x=\"class\", y=\"prob\", ax=ax, palette=colors)\n",
    "\n",
    "            labels_str = ['']*len(classes)\n",
    "            labels_str[label_pred] = f'{maxprob_i:.3f}'\n",
    "            for container in g1.containers:\n",
    "                ax.bar_label(container, labels=labels_str, label_type='edge')\n",
    "\n",
    "            ax.tick_params(axis='y', labelsize=7)\n",
    "            ax.set_xlabel(label_pred_des, fontsize=14)\n",
    "\n",
    "            # if rank_i in [4, 5]:\n",
    "            #     yname = 'Predictive Probability'\n",
    "            #     draw_single_barplot(df, classes,yname, ylimit, colors, label_gt_des)\n",
    "\n",
    "        elif yaxis == 'Self-Confidence':\n",
    "            ylimit = maxprobnll\n",
    "            ax.set_ylim([0, ylimit])\n",
    "            g2 = sns.barplot(df, x=\"class\", y=\"probnll\", ax=ax, palette=colors)\n",
    "\n",
    "            ######################\n",
    "            # add bar label\n",
    "            labels_str = ['']*len(classes)\n",
    "            labels_str[label_gt] = f'{probnll[label_gt]:.2f}'\n",
    "            for container in g2.containers:\n",
    "                ax.bar_label(container, labels=labels_str, label_type='edge')\n",
    "            ######################\n",
    "            ax.tick_params(axis='y', labelsize=9)\n",
    "            ax.set_xlabel(f'True={true_label_des}\\nAnno={label_gt_des}', fontsize=12)\n",
    "\n",
    "            # if rank_i in [4, 5]:\n",
    "            #     yname = 'Negative Log of Self-Confidence'\n",
    "            #     draw_single_barplot(df, classes,yname, ylimit, colors, label_gt_des)\n",
    "\n",
    "\n",
    "        elif yaxis == 'Normalized Margin':\n",
    "            ylimit = maxnmnll\n",
    "            ######################\n",
    "            # add bar label\n",
    "            g3=sns.barplot(df, x=\"class\", y=\"nmnll\", ax=ax, palette=colors)\n",
    "            labels_str = ['']*len(classes)\n",
    "            labels_str[label_gt] = f'{nmnll[label_gt]:.2f}'\n",
    "            for container in g3.containers:\n",
    "                ax.bar_label(container, labels=labels_str, label_type='edge')\n",
    "            ######################\n",
    "            ax.set_ylim([0, ylimit])\n",
    "            ax.tick_params(axis='y', labelsize=9)\n",
    "            ax.set_xlabel(f'True={true_label_des}\\nAnno={label_gt_des}', fontsize=12)\n",
    "\n",
    "            # if rank_i in [4, 5]:\n",
    "            #     yname = 'Negative Log of Normalized Margin'\n",
    "            #     draw_single_barplot(df, classes,yname, ylimit, colors, label_gt_des)\n",
    "        \n",
    "        # if rank_i < topn:\n",
    "        # print(f'probnll={probnll[class2id[classname]]}, prob={prob[class2id[classname]]}, nm={nm[class2id[classname]]}')\n",
    "\n",
    "        \n",
    "        ax.set(ylabel = '')\n",
    "        # ax.tick_params(axis='x', labelsize=26)\n",
    "        \n",
    "        # ax.get_legend().set_visible(False)\n",
    "        ax.set_xticks([])\n",
    "        # ax.set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{fig_path}', dpi=110)\n",
    "    plt.show()\n",
    "\n",
    "fig_dirpath = f'./postprocessing/fig/COCO_gdino_swinb/perclass_{classname}_{ranked_by}_{m_name}'\n",
    "\n",
    "\n",
    "if not os.path.isdir(fig_dirpath):\n",
    "    os.makedirs(fig_dirpath, exist_ok=True)\n",
    "\n",
    "yaxis = 'Predictive Probability'\n",
    "fig_path = f'{fig_dirpath}/{classname}_prob.png'\n",
    "draw_multirow(topn, class_df, yaxis, classname, classes, fig_path)\n",
    "# draw_multirow_single(topn, class_df, yaxis, classname, classes, fig_dirpath)\n",
    "\n",
    "yaxis = 'Self-Confidence'\n",
    "fig_path = f'{fig_dirpath}/{classname}_SC.png'\n",
    "draw_multirow(topn, class_df, yaxis, classname, classes, fig_path)\n",
    "# draw_multirow_single(topn, class_df, yaxis, classname, classes, fig_dirpath)\n",
    "\n",
    "yaxis = 'Normalized Margin'\n",
    "fig_path = f'{fig_dirpath}/{classname}_NM.png'\n",
    "draw_multirow(topn, class_df, yaxis, classname, classes, fig_path)\n",
    "# draw_multirow_single(topn, class_df, yaxis, classname, classes, fig_dirpath)\n",
    "\n",
    "########################################\n",
    "#                     Save single bbox images\n",
    "########################################\n",
    "cnt = 0\n",
    "for bbox_idx, row in class_df.iterrows():\n",
    "    img = np.array(Image.open(row['imgpath']))\n",
    "    if img.ndim ==2:\n",
    "        print(f'Convert gray image to RGB')\n",
    "        # Load the grayscale image \n",
    "        img_gray = Image.open(row['imgpath']).convert('L') \n",
    "\n",
    "        # Create a new RGB image with three identical grayscale channels \n",
    "        img = Image.merge('RGB', [img_gray]*3)\n",
    "        img = np.array(img)\n",
    "        \n",
    "    img_shape = img.shape\n",
    "\n",
    "    isshow = False\n",
    "    isfont = False\n",
    "    img_with_bbox = draw_bboxes(img, [row['bbox_gt']], [row['label_gt']], [row['label_gt_des']], [row['label_pred']], [row['label_pred_des']], name2RGB, name2white, isshow, isfont)\n",
    "\n",
    "    bbox_img = crop_bboxes(img_with_bbox, img_shape, [row['bbox_gt']], [row['label_gt']], pad=15)[0]\n",
    "\n",
    "    plt.imshow(bbox_img, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "\n",
    "    if not os.path.isdir(fig_dirpath):\n",
    "        os.makedirs(fig_dirpath, exist_ok=True)\n",
    "\n",
    "    # fig_dirpath = f'./postprocessing/fig/SHIFT_rcnn/perclass_{classname}_{ranked_by}'\n",
    "    imgname = row['imgpath'].replace('.jpg', '').replace('/', '_')\n",
    "\n",
    "    plt.savefig(f\"{fig_dirpath}/{classname}_{cnt}_{imgname}.png\", bbox_inches='tight')\n",
    "    \n",
    "\n",
    "    # print(f'bbox_idx={bbox_idx}, classname={classname}')\n",
    "    cnt += 1\n",
    "\n",
    "    if cnt > topn:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "#     bdd100k_det = {\n",
    "#     0: \"pedestrian\",\n",
    "#     1: \"rider\",\n",
    "#     2: \"car\",\n",
    "#     3: \"truck\",\n",
    "#     4: \"bus\",\n",
    "#     5: \"train\",\n",
    "#     6: \"motorcycle\",\n",
    "#     7: \"bicycle\",\n",
    "#     8: \"traffic light\",\n",
    "#     9: \"traffic sign\",\n",
    "#     10: \"bg\",\n",
    "# }\n",
    "\n",
    "# shift_det = {\n",
    "#     0: \"pedestrian\",\n",
    "#     1: \"car\",\n",
    "#     2: \"truck\",\n",
    "#     3: \"bus\",\n",
    "#     4: \"motorcycle\",\n",
    "#     5: \"bicycle\",\n",
    "#     6: \"bg\"\n",
    "# }\n",
    "\n",
    "# peak_mapper = {\n",
    "#     \"pedestrian\": \"bicycle\",\n",
    "#     \"car\": \"bus\",\n",
    "#     \"truck\": \"car\",\n",
    "#     \"bus\": \"truck\",\n",
    "#     \"motorcycle\": \"bicycle\",\n",
    "#     \"bicycle\": \"motorcycle\",\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-Test\n",
    "# effectiveness of Confident Joint (p-values over epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.stats import ttest_ind, ttest_rel, combine_pvalues\n",
    "\n",
    "# m_names = ['uni20', 'ass20', 'uni10', 'ass10', 'uni5', 'ass5', 'uni1', 'ass1']\n",
    "\n",
    "\n",
    "# auc_patk_dic_filepath = f'./postprocessing/code/DataFrame/{coco_gdino_backbone}/aed_auc/top200_patk_all.pkl'\n",
    "auc_patk_dic_filepath = f'./postprocessing/code/DataFrame/{coco_gdino_backbone}/aed_auc/cj_patk_all.pkl'\n",
    "auc_ratk_dic_filepath = f'./postprocessing/code/DataFrame/{coco_gdino_backbone}/aed_auc/cj_ratk_all.pkl'\n",
    "\n",
    "with open(auc_patk_dic_filepath, 'rb') as f:\n",
    "    auc_patk_dic = pickle.load(f)\n",
    "\n",
    "with open(auc_ratk_dic_filepath, 'rb') as f:\n",
    "    auc_ratk_dic = pickle.load(f)\n",
    "\n",
    "auc_dic = auc_ratk_dic\n",
    "\n",
    "def compare_effectiveness_cl(m_names, methods):\n",
    "    t_values = []\n",
    "    p_values = []\n",
    "\n",
    "    for m_name in m_names:\n",
    "        # df = perform_dic[m_name].copy()\n",
    "\n",
    "        for (rank, cl) in methods:\n",
    "            a=[i[0] for i in auc_dic[m_name][rank]['aucs']]\n",
    "            b=[i[0] for i in auc_dic[m_name][cl]['aucs']]\n",
    "\n",
    "            result = scipy.stats.ttest_rel(a, b, axis=0, alternative='two-sided')\n",
    "            t_values.append(result.statistic)\n",
    "            p_values.append(result.pvalue)\n",
    "            # print(f'{m_name}, {cl}, {rank}, t-value={result.statistic[0]}, p-value={result.pvalue[0]}')\n",
    "\n",
    "    # combined_pvalue = combine_pvalues(p_values,  method='fisher')\n",
    "    combined_pvalue = np.average(p_values)\n",
    "    # print(f'{m_name}, combined_pvalue={combined_pvalue[0]}, combined p-value={combined_pvalue[1]}')\n",
    "\n",
    "    return t_values, p_values, combined_pvalue\n",
    "\n",
    "def print_latex(auc_dic, m_names, methods):\n",
    "\n",
    "    for method in methods:\n",
    "        # every latex row\n",
    "        \n",
    "        auc_list = []\n",
    "        mean_list = []\n",
    "        std_list = []\n",
    "\n",
    "        for m_name in m_names:\n",
    "            auc_list =[100.0*i[0] for i in auc_dic[m_name][method]['aucs']]\n",
    "            auc_mean = np.mean(auc_list)\n",
    "            auc_std = np.std(auc_list, ddof=1)\n",
    "            mean_list.append(auc_mean)\n",
    "            std_list.append(auc_std)\n",
    "\n",
    "        mean_list = [f'{i:.1f}' for i in mean_list]\n",
    "        std_list = [f'{i:.1f}' for i in std_list]\n",
    "        row_str = ' & '.join([f'{i}$\\pm${j}' for i, j in zip(mean_list, std_list)])\n",
    "        row_str = f'{method} & {row_str} \\\\\\\\'\n",
    "        print(row_str)\n",
    "\n",
    "\n",
    "######################################\n",
    "#                                 Print Latex\n",
    "######################################\n",
    "# m_names = ['uni20', 'uni10', 'uni5', 'uni1', 'ass20', 'ass10', 'ass5', 'ass1']\n",
    "# methods = ['SC', 'CL_SC', 'NM', 'CL_NM']\n",
    "# print_latex(auc_dic, m_names, methods)\n",
    "\n",
    "######################################\n",
    "#                 Print Latex t-values and p-values\n",
    "######################################\n",
    "t_list =[]\n",
    "p_list = []\n",
    "print(f'----- Self-Confidence uniform noise -----')\n",
    "methods = [('SC', 'CL_SC')]\n",
    "m_names = ['uni20', 'uni10', 'uni5', 'uni1']\n",
    "t_values, p_values, combined_pvalue = compare_effectiveness_cl(m_names, methods)\n",
    "t_list.extend(t_values)\n",
    "p_list.extend(p_values)\n",
    "print(f'Combined p-value={combined_pvalue}')\n",
    "\n",
    "print(f'----- Self-Confidence asymmetric noise -----')\n",
    "methods = [('SC', 'CL_SC')]\n",
    "m_names = ['ass20', 'ass10', 'ass5', 'ass1']\n",
    "t_values, p_values, combined_pvalue = compare_effectiveness_cl(m_names, methods)\n",
    "t_list.extend(t_values)\n",
    "p_list.extend(p_values)\n",
    "print(f'Combined p-value={combined_pvalue}')\n",
    "\n",
    "\n",
    "# print(f'----- Self-Confidence uniform+asymmetric noise -----')\n",
    "# methods = [('SC', 'CL_SC')]\n",
    "# m_names = ['uni20', 'uni10', 'uni5', 'uni1', 'ass20', 'ass10', 'ass5', 'ass1']\n",
    "# t_values, p_values, combined_pvalue = compare_effectiveness_cl(m_names, methods)\n",
    "# print(f'Combined p-value={combined_pvalue}')\n",
    "\n",
    "tvalue_latex = ' & '.join([f'{i:.2f}' for i in t_list])\n",
    "pvalue_latex = ' & '.join([f'{i:.2f}' for i in p_list])\n",
    "print(f't-values = {tvalue_latex}')\n",
    "print(f'p-values = {pvalue_latex}')\n",
    "\n",
    "\n",
    "print(' ')\n",
    "t_list =[]\n",
    "p_list = []\n",
    "print(f'----- Normalized Margin uniform noise -----')\n",
    "methods = [('NM', 'CL_NM')]\n",
    "m_names = ['uni20', 'uni10', 'uni5', 'uni1']\n",
    "t_values, p_values, combined_pvalue = compare_effectiveness_cl(m_names, methods)\n",
    "t_list.extend(t_values)\n",
    "p_list.extend(p_values)\n",
    "print(f'Combined p-value={combined_pvalue}')\n",
    "\n",
    "\n",
    "print(f'----- Normalized Margin asymmetric noise -----')\n",
    "methods = [('NM', 'CL_NM')]\n",
    "m_names = ['ass20', 'ass10', 'ass5', 'ass1']\n",
    "t_values, p_values, combined_pvalue = compare_effectiveness_cl(m_names, methods)\n",
    "t_list.extend(t_values)\n",
    "p_list.extend(p_values)\n",
    "print(f'Combined p-value={combined_pvalue}')\n",
    "\n",
    "\n",
    "# print(f'----- Normalized Margin uniform+asymmetric noise -----')\n",
    "# methods = [('NM', 'CL_NM')]\n",
    "# m_names = ['uni20', 'uni10', 'uni5', 'uni1', 'ass20', 'ass10', 'ass5', 'ass1']\n",
    "# t_values, p_values, combined_pvalue = compare_effectiveness_cl(m_names, methods)\n",
    "# print(f'Combined p-value={combined_pvalue}')\n",
    "\n",
    "\n",
    "\n",
    "tvalue_latex = ' & '.join([f'{i:.2f}' for i in t_list])\n",
    "pvalue_latex = ' & '.join([f'{i:.2f}' for i in p_list])\n",
    "print(f't-values = {tvalue_latex}')\n",
    "print(f'p-values = {pvalue_latex}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Ranking Efficacy\n",
    "# Normalized Margin is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.stats import ttest_ind, ttest_rel, combine_pvalues\n",
    "\n",
    "# m_names = ['uni20', 'ass20', 'uni10', 'ass10', 'uni5', 'ass5', 'uni1', 'ass1']\n",
    "\n",
    "\n",
    "# auc_patk_dic_filepath = f'./postprocessing/code/DataFrame/{coco_gdino_backbone}/aed_auc/top200_patk_all.pkl'\n",
    "auc_patk_dic_filepath = f'./postprocessing/code/DataFrame/{coco_gdino_backbone}/aed_auc/top2000_patk_all.pkl'\n",
    "# auc_patk_dic_filepath = f'./postprocessing/code/DataFrame/{coco_gdino_backbone}/aed_auc/cj_patk_all.pkl'\n",
    "# auc_ratk_dic_filepath = f'./postprocessing/code/DataFrame/{coco_gdino_backbone}/aed_auc/cj_ratk_all.pkl'\n",
    "\n",
    "with open(auc_patk_dic_filepath, 'rb') as f:\n",
    "    auc_patk_dic = pickle.load(f)\n",
    "\n",
    "# with open(auc_ratk_dic_filepath, 'rb') as f:\n",
    "#     auc_ratk_dic = pickle.load(f)\n",
    "\n",
    "auc_dic = auc_patk_dic\n",
    "\n",
    "def compare_effectiveness_cl(m_names, methods):\n",
    "    t_values = []\n",
    "    p_values = []\n",
    "\n",
    "    for m_name in m_names:\n",
    "        # df = perform_dic[m_name].copy()\n",
    "\n",
    "        for (cl, rank) in methods:\n",
    "            a=auc_dic[m_name][cl]['aucs']\n",
    "            b=auc_dic[m_name][rank]['aucs']\n",
    "\n",
    "            result = scipy.stats.ttest_rel(a, b, axis=0, alternative='two-sided')\n",
    "            t_values.append(result.statistic)\n",
    "            p_values.append(result.pvalue)\n",
    "            # print(f'{m_name}, {cl}, {rank}, t-value={result.statistic[0]}, p-value={result.pvalue[0]}')\n",
    "\n",
    "    # combined_pvalue = combine_pvalues(p_values,  method='fisher')\n",
    "    combined_pvalue = np.average(p_values)\n",
    "    # print(f'{m_name}, combined_pvalue={combined_pvalue[0]}, combined p-value={combined_pvalue[1]}')\n",
    "\n",
    "    return t_values, p_values, combined_pvalue\n",
    "\n",
    "t_list = []\n",
    "p_list = []\n",
    "print(f'----- SC vs NM uniform noise -----')\n",
    "methods = [('SC', 'NM')]\n",
    "m_names = ['uni20', 'uni10', 'uni5', 'uni1']\n",
    "t_values, p_values, combined_pvalue = compare_effectiveness_cl(m_names, methods)\n",
    "t_list.extend(t_values)\n",
    "p_list.extend(p_values)\n",
    "print(f'Combined p-value={combined_pvalue}')\n",
    "\n",
    "print(f'----- SC vs NM asymmetric noise -----')\n",
    "methods = [('SC', 'NM')]\n",
    "m_names = ['ass20', 'ass10', 'ass5', 'ass1']\n",
    "t_values, p_values, combined_pvalue = compare_effectiveness_cl(m_names, methods)\n",
    "t_list.extend(t_values)\n",
    "p_list.extend(p_values)\n",
    "print(f'Combined p-value={combined_pvalue}')\n",
    "\n",
    "tvalue_latex = ' & '.join([f'{i:.2f}' for i in t_list])\n",
    "pvalue_latex = ' & '.join([f'{i:.2f}' for i in p_list])\n",
    "print(f't-values = {tvalue_latex}')\n",
    "print(f'p-values = {pvalue_latex}')\n",
    "\n",
    "##########################################\n",
    "t_list = []\n",
    "p_list = []\n",
    "print(f'----- CL_SC vs CL_NM uniform noise -----')\n",
    "methods = [('CL_SC', 'CL_NM')]\n",
    "m_names = ['uni20', 'uni10', 'uni5', 'uni1']\n",
    "t_values, p_values, combined_pvalue = compare_effectiveness_cl(m_names, methods)\n",
    "t_list.extend(t_values)\n",
    "p_list.extend(p_values)\n",
    "print(f'Combined p-value={combined_pvalue}')\n",
    "\n",
    "print(f'----- CL_SC vs CL_NM asymmetric noise -----')\n",
    "methods = [('CL_SC', 'CL_NM')]\n",
    "m_names = ['ass20', 'ass10', 'ass5', 'ass1']\n",
    "t_values, p_values, combined_pvalue = compare_effectiveness_cl(m_names, methods)\n",
    "t_list.extend(t_values)\n",
    "p_list.extend(p_values)\n",
    "print(f'Combined p-value={combined_pvalue}')\n",
    "\n",
    "\n",
    "\n",
    "tvalue_latex = ' & '.join([f'{i:.2f}' for i in t_list])\n",
    "pvalue_latex = ' & '.join([f'{i:.2f}' for i in p_list])\n",
    "print(f't-values = {tvalue_latex}')\n",
    "print(f'p-values = {pvalue_latex}')\n",
    "\n",
    "\n",
    "# print(' ')\n",
    "# print(f'----- Normalized Margin uniform noise -----')\n",
    "# methods = [('NM', 'CL_NM')]\n",
    "# m_names = ['uni20', 'uni10', 'uni5', 'uni1']\n",
    "# t_values, p_values, combined_pvalue = compare_effectiveness_cl(m_names, methods)\n",
    "# print(f'Combined p-value={combined_pvalue}')\n",
    "\n",
    "\n",
    "# print(f'----- Normalized Margin asymmetric noise -----')\n",
    "# methods = [('NM', 'CL_NM')]\n",
    "# m_names = ['ass20', 'ass10', 'ass5', 'ass1']\n",
    "# t_values, p_values, combined_pvalue = compare_effectiveness_cl(m_names, methods)\n",
    "# print(f'Combined p-value={combined_pvalue}')\n",
    "\n",
    "\n",
    "# print(f'----- Normalized Margin uniform+asymmetric noise -----')\n",
    "# methods = [('NM', 'CL_NM')]\n",
    "# m_names = ['uni20', 'uni10', 'uni5', 'uni1', 'ass20', 'ass10', 'ass5', 'ass1']\n",
    "# t_values, p_values, combined_pvalue = compare_effectiveness_cl(m_names, methods)\n",
    "# print(f'Combined p-value={combined_pvalue}')\n",
    "\n",
    "\n",
    "\n",
    "# tvalue_latex = ' & '.join([f'{i:.2f}' for i in t_values])\n",
    "# pvalue_latex = ' & '.join([f'{i:.2f}' for i in p_values])\n",
    "# print(f't-values = {tvalue_latex}')\n",
    "# print(f'p-values = {pvalue_latex}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Correlation between Model performance and AED performance\n",
    "## All epoch, to use more sample points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "m_names = ['uni20', 'ass20', 'uni10', 'ass10', 'uni5', 'ass5', 'uni1', 'ass1']\n",
    "methods = ['SC', 'CL_SC', 'NM','CL_NM']\n",
    "epos = list(range(1, 6))\n",
    "\n",
    "# auc_patk_dic_filepath = f'./postprocessing/code/DataFrame/{coco_gdino_backbone}/aed_auc/top200_patk_all.pkl'\n",
    "auc_patk_dic_filepath = f'./postprocessing/code/DataFrame/{coco_gdino_backbone}/aed_auc/top2000_patk_all.pkl'\n",
    "# auc_patk_dic_filepath = f'./postprocessing/code/DataFrame/{coco_gdino_backbone}/aed_auc/cj_patk_all.pkl'\n",
    "# auc_ratk_dic_filepath = f'./postprocessing/code/DataFrame/{coco_gdino_backbone}/aed_auc/cj_ratk_all.pkl'\n",
    "\n",
    "columns = ['epoch', 'model_precision', 'aed_patk', 'aed_method', 'noise_pattern']\n",
    "\n",
    "\n",
    "with open(auc_patk_dic_filepath, 'rb') as f:\n",
    "    auc_patk_dic = pickle.load(f)\n",
    "\n",
    "# with open(auc_ratk_dic_filepath, 'rb') as f:\n",
    "#     auc_ratk_dic = pickle.load(f)\n",
    "\n",
    "auc_dic = auc_patk_dic\n",
    "\n",
    "precision_mi_list = []\n",
    "method_auc ={m: [] for m in methods}\n",
    "correlation_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for m_name in m_names:\n",
    "    model_perf_df = perform_dic[m_name].copy()\n",
    "\n",
    "    precision_ma = model_perf_df['precision_ma'].values.tolist()\n",
    "    recall_ma = model_perf_df['recall_ma'].values.tolist()\n",
    "    # f1_ma = df['f1_ma'].values.tolist()\n",
    "\n",
    "    precision_mi = model_perf_df['precision_mi'].values.tolist()\n",
    "    recall_mi = model_perf_df['recall_mi'].values.tolist()\n",
    "    # f1_mi = df['f1_mi'].values.tolist()\n",
    "\n",
    "    precision_mi_list.extend(precision_mi)\n",
    "\n",
    "    auc_result = auc_dic[m_name]\n",
    "\n",
    "    for method in methods:\n",
    "        aed_patk = auc_patk_dic[m_name][method]['aucs']\n",
    "        # aed_ratk = auc_ratk_dic[m_name][method]['aucs']\n",
    "        # aed_patk = [i[0] for i in aed_patk]\n",
    "        # aed_ratk = [i[0] for i in aed_ratk]\n",
    "        method_list = [method]*len(aed_patk)\n",
    "        noise_pattern_list = [m_name]*len(aed_patk)\n",
    "        epos = list(range(1, len(aed_patk)+1))\n",
    "\n",
    "        method_auc[method].extend(method * len(aed_patk))\n",
    "\n",
    "        row_df = pd.DataFrame(list(zip(epos, precision_mi, aed_patk, method_list, noise_pattern_list)), columns=columns)\n",
    "        correlation_df = pd.concat([correlation_df, row_df], ignore_index=True)\n",
    "    \n",
    "    print('')\n",
    "\n",
    "\n",
    "\n",
    "def cal_correlation(stat, model_perf_list, method_auc):\n",
    "    if stat == 'spearmanr':\n",
    "        sc = spearmanr(model_perf_list, method_auc['SC'], alternative='two-sided')\n",
    "        cl_sc = spearmanr(model_perf_list, method_auc['CL_SC'], alternative='two-sided')\n",
    "        nm = spearmanr(model_perf_list, method_auc['NM'], alternative='two-sided')\n",
    "        cl_nm = spearmanr(model_perf_list, method_auc['CL_NM'], alternative='two-sided')\n",
    "\n",
    "    elif stat == 'pearsonr':\n",
    "        sc = pearsonr(model_perf_list, method_auc['SC'], alternative='two-sided')\n",
    "        cl_sc = pearsonr(model_perf_list, method_auc['CL_SC'], alternative='two-sided')\n",
    "        nm = pearsonr(model_perf_list, method_auc['NM'], alternative='two-sided')\n",
    "        cl_nm = pearsonr(model_perf_list, method_auc['CL_NM'], alternative='two-sided')\n",
    "\n",
    "\n",
    "    print(f'{stat}')\n",
    "    print(f'SC={sc}')\n",
    "    print(f'CL_SC={cl_sc}')\n",
    "    print(f'NM={nm}')\n",
    "    print(f'CL_NM={cl_nm}')\n",
    "\n",
    "\n",
    "# df = pd.DataFrame({'model_precision': precision_mi_list, 'SC': method_auc['SC'], 'CL_SC': method_auc['CL_SC'], 'NM': method_auc['NM'], 'CL_NM': method_auc['CL_NM']})\n",
    "\n",
    "# df = pd.melt(df, id_vars=['model_precision'], value_vars=['SC', 'CL_SC', 'NM', 'CL_NM'])\n",
    "\n",
    "def draw_scatterplot(df, xaxis, yaxis, hue, is_range01):\n",
    "    plt.figure(figsize=(7, 5))\n",
    "\n",
    "    if hue == 'epoch' :\n",
    "        hue_order = df['epoch'].unique().tolist()\n",
    "        palette_colors = sns.color_palette(\"ch:start=.2,rot=-.3\", len(hue_order))\n",
    "        palette_dict = {l: color for l, color in zip(hue_order, palette_colors)}\n",
    "        ax = sns.scatterplot(df, x=xaxis, y=yaxis, hue=hue, hue_order=hue_order, palette=palette_dict)\n",
    "\n",
    "    elif hue == 'noise_pattern':\n",
    "        hue_order = m_names\n",
    "        ax = sns.scatterplot(df, x=xaxis, y=yaxis, hue=hue, hue_order=hue_order)\n",
    "    else:\n",
    "        ax = sns.scatterplot(df, x=xaxis, y=yaxis, hue=hue)\n",
    "\n",
    "    if is_range01 is True:\n",
    "        plt.xlim(0, 1)\n",
    "        plt.ylim(0, 1)\n",
    "\n",
    "    ax.legend(bbox_to_anchor=(1, 1))\n",
    "\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize=20)\n",
    "    ax.set(xlabel='', ylabel = '')\n",
    "    ax.tick_params(axis='x', labelsize=26)\n",
    "    ax.tick_params(axis='y', labelsize=22)\n",
    "    # ax.get_legend().set_visible(False)\n",
    "\n",
    "    plt.grid(linewidth = 0.5)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f'{tmp_figpath}', dpi=80)\n",
    "    plt.show()\n",
    "    \n",
    "    category_aed_methods = pd.api.types.CategoricalDtype(categories=methods, ordered=True)\n",
    "    df['aed_method'] = df['aed_method'].astype(category_aed_methods)\n",
    "\n",
    "    grouped_df = None\n",
    "    if hue == 'noise_pattern':\n",
    "        category_hue = pd.api.types.CategoricalDtype(categories=m_names, ordered=True)\n",
    "        df[hue] = df[hue].astype(category_hue)\n",
    "        grouped_df = df.groupby([hue, 'aed_method'])\n",
    "        print('')\n",
    "\n",
    "    elif hue == 'epoch':\n",
    "        category_hue = pd.api.types.CategoricalDtype(categories=list(range(1, 9)), ordered=True)\n",
    "        df[hue] = df[hue].astype(category_hue)\n",
    "        grouped_df = df.groupby([hue, 'aed_method'])\n",
    "        print('')\n",
    "    else:\n",
    "        grouped_df = df.groupby([hue])\n",
    "\n",
    "\n",
    "    corr_dic = {}\n",
    "    for name, group in grouped_df:\n",
    "        print(f'----- {name} -----')\n",
    "        corr_a = group[xaxis]\n",
    "        corr_b = group[yaxis]\n",
    "\n",
    "        print(f'Sample size = {len(corr_a)}')\n",
    "\n",
    "        pear_cc = pearsonr(corr_a, corr_b, alternative='two-sided')\n",
    "        spear_cc = spearmanr(corr_a, corr_b, alternative='two-sided')\n",
    "        print(f'pearsonr={pear_cc}')\n",
    "        print(f'spearmanr={spear_cc}')\n",
    "        corr_dic.update({name: [pear_cc, spear_cc]})\n",
    "\n",
    "    return corr_dic\n",
    "\n",
    "\n",
    "\n",
    "def print_latex(corr_dic, col_order, row_order):\n",
    "\n",
    "    for row in row_order:\n",
    "        print(f'----- {row} -----')\n",
    "        pear_t_str = ''\n",
    "        pear_p_str = ''\n",
    "        spear_t_str = ''\n",
    "        spear_p_str = ''\n",
    "\n",
    "        cnt = 0\n",
    "        pear_p_list = []\n",
    "        spear_p_list = []\n",
    "\n",
    "        for col in col_order:\n",
    "            pear_cc = corr_dic[(col, row)][0]\n",
    "            pear_t_str += f' & {pear_cc.statistic:.2f}'\n",
    "            pear_p_str += f' & {pear_cc.pvalue:.2f}'\n",
    "            pear_p_list.append(pear_cc.pvalue)\n",
    "\n",
    "            spear_cc = corr_dic[(col, row)][1]\n",
    "            spear_t_str += f' & {spear_cc.statistic:.2f}'\n",
    "            spear_p_str += f' & {spear_cc.pvalue:.2f}'\n",
    "            spear_p_list.append(spear_cc.pvalue)\n",
    "\n",
    "            cnt+=1\n",
    "            if cnt == 4:\n",
    "                pear_avg = np.average(pear_p_list)\n",
    "                spear_avg = np.average(spear_p_list)\n",
    "                # print(f'Combined pearsonr p-value={pear_avg:.3f}')\n",
    "                print(f'Combined spearmanr p-value={spear_avg:.3f}')\n",
    "                pear_p_list = []\n",
    "                spear_p_list = []\n",
    "                cnt = 0\n",
    "\n",
    "\n",
    "        # row_str += '\\\\\\\\'\n",
    "        # print(f'pear_t_str={pear_t_str}')\n",
    "        # print(f'pear_p_str={pear_p_str}')\n",
    "        print(f'spear_t_str={spear_t_str}')\n",
    "        print(f'spear_p_str={spear_p_str}')\n",
    "\n",
    "\n",
    "\n",
    "########################################################\n",
    "\n",
    "correlation_pair = 'precision'\n",
    "# correlation_pair = 'recall'\n",
    "\n",
    "if correlation_pair == 'precision':\n",
    "    xaxis = 'model_precision'\n",
    "    yaxis = 'aed_patk'\n",
    "elif correlation_pair == 'recall':\n",
    "    xaxis = 'model_recall'\n",
    "    yaxis = 'aed_ratk'\n",
    "\n",
    "\n",
    "is_range01 = True\n",
    "hue = 'aed_method'\n",
    "draw_scatterplot(correlation_df, xaxis, yaxis, hue, is_range01)\n",
    "\n",
    "is_range01 = False\n",
    "hue = 'noise_pattern'\n",
    "corr_dic = draw_scatterplot(correlation_df, xaxis, yaxis, hue, is_range01)\n",
    "col_order = ['uni20', 'uni10', 'uni5', 'uni1', 'ass20', 'ass10', 'ass5', 'ass1']\n",
    "row_order = ['SC', 'CL_SC', 'NM', 'CL_NM']\n",
    "print_latex(corr_dic, col_order, row_order)\n",
    "\n",
    "is_range01 = False\n",
    "hue = 'epoch'\n",
    "draw_scatterplot(correlation_df, xaxis, yaxis, hue, is_range01)\n",
    "\n",
    "\n",
    "\n",
    "# correlation_df[xaxis]\n",
    "\n",
    "# stat = 'pearsonr'\n",
    "# cal_correlation(stat, precision_mi_list, method_auc)\n",
    "\n",
    "# stat = 'spearmanr'\n",
    "# cal_correlation(stat, precision_mi_list, method_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check TopN AED Precision TP/FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "\n",
    "rounds = list(range(1, 6))\n",
    "\n",
    "m_names = ['uni20', 'uni10', 'uni5', 'uni1', 'ass20', 'ass10', 'ass5', 'ass1']\n",
    "\n",
    "\n",
    "###############################################################\n",
    "#                 Number of Detected data                     #\n",
    "###############################################################\n",
    "\n",
    "# Selected methods\n",
    "# methods = ['EN','REN']\n",
    "# methods = ['CL_SC', 'SC', 'CL_RC', 'RC', 'LRank', 'CL_NM', 'NM', 'CL_EN', 'EN', 'CL_REN','REN', 'CL_CWE']\n",
    "methods = ['CL_SC', 'SC', 'LRank', 'CL_NM', 'NM']\n",
    "\n",
    "\n",
    "def cal_precision(df, detected_idxs, include_ambi, is_recall=False):\n",
    "\n",
    "    retrieved_elems = df.loc[detected_idxs, :]\n",
    "\n",
    "\n",
    "    if include_ambi is True:\n",
    "        TP_condition = (retrieved_elems['c_incorrect'] == True) | (retrieved_elems['ambiguous'] == True) \n",
    "    else:\n",
    "        TP_condition = (retrieved_elems['c_incorrect'] == True)\n",
    "\n",
    "    TP_df = retrieved_elems.loc[TP_condition]\n",
    "    FP_df = retrieved_elems.loc[(retrieved_elems['c_incorrect'] == False)]\n",
    "\n",
    "    if (len(TP_df)+len(FP_df)) == 0:\n",
    "        return 0, 0, 0, 0, 0\n",
    "\n",
    "    precision = 100.0 * len(TP_df) / (len(TP_df)+len(FP_df))\n",
    "\n",
    "    # print(f'detected_idxs={len(detected_idxs)}, TP={len(TP_df)}, FP={len(FP_df)}, Precision: {precision:.3f}%')\n",
    "    # assert (len(TP_df)+len(FP_df)) == len(detected_idxs)\n",
    "\n",
    "    recall = None\n",
    "    if is_recall:\n",
    "        relevant_elems = df.loc[df['c_incorrect']==True, :]\n",
    "\n",
    "        if len(relevant_elems) > 0:\n",
    "            recall = 100.0 * len(TP_df) / (len(relevant_elems))\n",
    "        else:\n",
    "            recall = 0.0\n",
    "        # FN_df = relevant_elems.loc[~relevant_elems.index.isin(detected_idxs), :]\n",
    "        # assert len(TP_df) + len(FP_df) + len(FN_df) == len(df)\n",
    "\n",
    "    TN_FP_condition = (df['c_incorrect'] == False)\n",
    "    TN_FP_df = df.loc[TN_FP_condition, :]\n",
    "    TN_df = TN_FP_df.loc[~TN_FP_df.index.isin(detected_idxs), :]\n",
    "\n",
    "    TNR = 100.0 *  len(TN_df) / len(TN_FP_df)\n",
    "\n",
    "    return len(TP_df), len(FP_df), precision, recall, TNR\n",
    "\n",
    "\n",
    "def gen_cal_df(m_names, methods, by_classes=False):\n",
    "    \n",
    "    cal_dic = {m: {ri:{method:{} for method in methods} for ri in rounds} for m in m_names}\n",
    "    cal_ambi_dic = {m: {ri:{method:{} for method in methods} for ri in rounds} for m in m_names}\n",
    "\n",
    "    total_incorrects = {m: {} for m in m_names}\n",
    "\n",
    "    for m_name in m_names:\n",
    "        print(f'-----------------Model {m_name} -----------------')\n",
    "        for ri in rounds:\n",
    "            # df_cal = pd.DataFrame(columns=colnames)\n",
    "\n",
    "            \n",
    "            # for epo in epos:\n",
    "            # print(f'Processing epoch {epo}')\n",
    "\n",
    "            epo_df = m_dic[m_name][ri].copy()\n",
    "\n",
    "            # csv_filename = f'swe_{m_name}_epo{epo}.csv'\n",
    "            # epo_df = pd.read_csv(f'{csv_dirpath}/{m_name}/{csv_filename}', index_col=0, header=0)\n",
    "            # epo_df['prob'] = epo_df['prob'].apply(lambda x: np.asarray(x.split(';'), dtype=float))\n",
    "            \n",
    "            # accuracy for each method (without Lrank)\n",
    "            for method in methods:\n",
    "\n",
    "                top_percentage = 1.0\n",
    "                # print(f'Processing method {method}')\n",
    "\n",
    "                if by_classes is False:\n",
    "                    classname = 'all'\n",
    "                    total_incorrects[m_name].update({classname: len(epo_df.loc[epo_df['c_incorrect']==True])})\n",
    "                \n",
    "                    if method == 'LRank':\n",
    "                        # topn_thresh = int(round(len(epo_df.loc[epo_df['CL_SC'] != 999999]) * top_percentage))\n",
    "\n",
    "\n",
    "                        # print(f'topNthresh={topNthresh} for LRank')\n",
    "                        detected_df = epo_df.sort_values(by='loss', ascending=False)\n",
    "                        epo_df.sort_values(by='loss', ascending=False, inplace=True)\n",
    "                        # detected_df = lossrank_df[:topn_thresh]\n",
    "                        # detected_df = epo_df.loc[epo_df[method] <= topNthresh]\n",
    "                    \n",
    "                    elif method  in ['NM', 'SC', 'EN']:\n",
    "                        # cl_idxs = epo_df.loc[epo_df['CL_SC'] != 999999].index.values\n",
    "\n",
    "                        detected_df = epo_df.sort_values(by=method, ascending=True)\n",
    "                        epo_df.sort_values(by=method, ascending=True, inplace=True)\n",
    "\n",
    "                    elif method  in ['REN', 'RC']:\n",
    "                        # cl_idxs = epo_df.loc[epo_df['CL_SC'] != 999999].index.values\n",
    "\n",
    "                        # For entropy and relative entropy\n",
    "                        # higher the better\n",
    "                        detected_df = epo_df.sort_values(by=method, ascending=False)\n",
    "                        epo_df.sort_values(by=method, ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        detected_df = epo_df.loc[epo_df[method] != 999999].sort_values(by=method, ascending=True)\n",
    "                        epo_df.sort_values(by=method, ascending=True, inplace=True)\n",
    "\n",
    "                        # detected_df = epo_df.loc[epo_df[method] != 999999].sort_values(by=method, ascending=True)\n",
    "                        # topn = int(round(len(detected_df) * top_percentage))\n",
    "                        # detected_df = detected_df[:topn]\n",
    "\n",
    "\n",
    "                    detected_idxs = detected_df.index.tolist()\n",
    "\n",
    "                    incorrects = epo_df['c_incorrect'].apply(lambda x: 'FN' if x is True else 'TN')\n",
    "                    true_labels_des = epo_df['true_label_des']\n",
    "                    labels_gt_des = epo_df['label_gt_des']\n",
    "                    labels_pred_des = epo_df['label_pred_des']\n",
    "                    incorrects_subset = incorrects[detected_idxs].apply(lambda x: 'TP' if x == 'FN' else 'FP')\n",
    "                    incorrects.update(incorrects_subset)\n",
    "\n",
    "                    cal_dic[m_name][ri][method].update({classname: incorrects})\n",
    "                    cal_dic[m_name][ri][method].update({'true_labels_des': true_labels_des})\n",
    "                    cal_dic[m_name][ri][method].update({'labels_gt_des': labels_gt_des})\n",
    "                    cal_dic[m_name][ri][method].update({'labels_pred_des': labels_pred_des})\n",
    "\n",
    "                else:\n",
    "\n",
    "                    for classname in id2class.values():\n",
    "\n",
    "                        class_df =epo_df.loc[epo_df['label_gt_des']==classname, :]\n",
    "\n",
    "                        total_incorrects[m_name].update({classname: len(class_df.loc[class_df['c_incorrect']==True])})\n",
    "                        # class_df =epo_df.loc[epo_df['label_gt_des']==classname, :]\n",
    "\n",
    "                        if len(class_df) == 0:\n",
    "                            print(f'No data for {classname} in epoch {epo}')\n",
    "                \n",
    "                        if method == 'LRank':\n",
    "                            # topn_thresh = int(round(len(class_df.loc[class_df['CL_SC'] != 999999]) * top_percentage))\n",
    "\n",
    "\n",
    "                            # print(f'topNthresh={topNthresh} for LRank')\n",
    "                            detected_df = class_df.sort_values(by='loss', ascending=False)\n",
    "                            class_df.sort_values(by='loss', ascending=False, inplace=True)\n",
    "\n",
    "                            # detected_df = lossrank_df[:topn_thresh]\n",
    "                            # detected_df = class_df.loc[class_df[method] <= topNthresh]\n",
    "                        \n",
    "                        elif method  in ['NM', 'SC', 'EN']:\n",
    "                            # cl_idxs = class_df.loc[class_df['CL_SC'] != 999999].index.values\n",
    "\n",
    "                            detected_df = class_df.sort_values(by=method, ascending=True)\n",
    "                            class_df.sort_values(by=method, ascending=True, inplace=True)\n",
    "\n",
    "\n",
    "                        elif method  in ['REN', 'RC']:\n",
    "                            # cl_idxs = class_df.loc[class_df['CL_SC'] != 999999].index.values\n",
    "\n",
    "                            detected_df = class_df.sort_values(by=method, ascending=False)\n",
    "                            class_df.sort_values(by=method, ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "                        else:\n",
    "                            detected_df = class_df.loc[class_df[method] != 999999].sort_values(by=method, ascending=True)\n",
    "                            class_df.sort_values(by=method, ascending=True, inplace=True)\n",
    "\n",
    "                            # topn = int(round(len(detected_df) * top_percentage))\n",
    "                            # detected_df = detected_df[:topn]\n",
    "\n",
    "\n",
    "                        detected_idxs = detected_df.index.tolist()\n",
    "\n",
    "                        # incorrects = class_df.loc[detected_idxs, 'c_incorrect'].apply(lambda x: 'TP' if x is True else 'FP').values\n",
    "                        # incorrects = class_df['c_incorrect'].apply(lambda x: 'FN' if x is True else 'TN')\n",
    "                        # incorrects = incorrects[detected_idxs].apply(lambda x: 'TP' if x == 'FN' else 'FP')\n",
    "                        incorrects = class_df['c_incorrect'].apply(lambda x: 'FN' if x is True else 'TN')\n",
    "                        incorrects_subset = incorrects[detected_idxs].apply(lambda x: 'TP' if x == 'FN' else 'FP')\n",
    "                        incorrects.update(incorrects_subset)\n",
    "\n",
    "                        cal_dic[m_name][ri][method].update({classname: incorrects})\n",
    "\n",
    "\n",
    "        # cal_dic[m_name] = df_cal\n",
    "\n",
    "            print(f'-----------------End of m_name {m_name}-----------------')\n",
    "\n",
    "    return cal_dic, total_incorrects\n",
    "\n",
    "topn_dic, total_incorrects = gen_cal_df(m_names, methods, by_classes=False)\n",
    "topn_byclass_dic, total_byclass_incorrects = gen_cal_df(m_names, methods, by_classes=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# def save_pkl(obj, filepath):\n",
    "#     with open(filepath, 'wb') as f:\n",
    "#         pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# def read_pkl(filepath):\n",
    "#     with open(filepath, 'rb') as f:\n",
    "#         data = pickle.load(f)\n",
    "#     return data\n",
    "\n",
    "# aed_perf_dirpath = f'./postprocessing/code/DataFrame/{coco_gdino_backbone}/aed_topn'\n",
    "\n",
    "\n",
    "# aed_perf_filename = f'aed_topn'\n",
    "# aed_perf_filepath = f'{aed_perf_dirpath}/aed_topn_{subset}.pkl'\n",
    "\n",
    "# ###########################\n",
    "# #                            Save file\n",
    "# aed_topn_obj = {\n",
    "#     'all': topn_dic,\n",
    "#     'all_incorrect': total_incorrects,\n",
    "#     'byclass': topn_byclass_dic, \n",
    "#     'byclass_incorrect': total_byclass_incorrects\n",
    "# }\n",
    "# save_pkl(aed_topn_obj, aed_perf_filepath)\n",
    "# print(f'Saved to {aed_perf_filepath}')\n",
    "\n",
    "# ###########################\n",
    "# #                          Read file\n",
    "# # aed_topn = read_pkl(aed_perf_filepath)\n",
    "\n",
    "# # topn_dic = aed_topn['all']\n",
    "# # total_incorrects = aed_topn['all_incorrect']\n",
    "# # topn_byclass_dic = aed_topn['byclass']\n",
    "# # total_byclass_incorrects = aed_topn['byclass_incorrect']\n",
    "# # print(f'Read aed_topn {aed_perf_filepath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newly Updated Check cal_dic and cal_byclass_dic (total items: 211998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn_dic['uni20']['CL_SC']['labels_pred_des']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot AED TopN Precision, Cumsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def convert_cumsum(tpfp_list, topn, interval):\n",
    "    num_tps = []\n",
    "    precisions = []\n",
    "    for i in range(0, topn, interval):\n",
    "        start = i\n",
    "        end = i + (interval-1)\n",
    "        if len(tpfp_list[start:end]) == 0:\n",
    "            num_tp = 0\n",
    "        else:\n",
    "            num_tp = sum(tpfp_list[start:end] == 'TP')\n",
    "\n",
    "            if len(tpfp_list[start:end]) == 0:\n",
    "                precision = 0\n",
    "            else:\n",
    "                precision = 100.0*sum(tpfp_list[start:end] == 'TP') / len(tpfp_list[start:end])\n",
    "\n",
    "        num_tps.append(num_tp)\n",
    "        precisions.append(precision)\n",
    "\n",
    "    cumsum = np.cumsum(num_tps)\n",
    "\n",
    "    return num_tps, cumsum, precisions\n",
    "\n",
    "\n",
    "def draw_precision_segment_cum_std(df, x, total_num, ftitle, topn, interval, y, hue, show_total):\n",
    "    # if len(df) == 0:\n",
    "    #     return\n",
    "    dpi = 50\n",
    "    fig = plt.figure(dpi=dpi, figsize=(15,8))\n",
    "    sns.set_theme(style=\"whitegrid\", font=\"serif\")\n",
    "    sns.set_palette(\"Paired\")\n",
    "    \n",
    "    linewidth = 5\n",
    "\n",
    "    if hue == 'Epoch':\n",
    "        ax = sns.lineplot(x='Interval', y=y, data=df, hue=hue, linewidth=linewidth, legend='full')\n",
    "    else:\n",
    "        ax = sns.lineplot(x='Interval', y=y, data=df, hue=hue, linewidth=linewidth, err_style=\"bars\", errorbar=(\"se\", 2))\n",
    "\n",
    "    leg = ax.legend()\n",
    "    for i in leg.legendHandles:\n",
    "        i.set_linewidth(5)\n",
    "    # sns.move_legend(ax, \"lower left\")\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize=22)\n",
    "    # ax.legend(fontsize=22)\n",
    "    ax.set(xlabel='', ylabel = '')\n",
    "    ax.tick_params(axis='x', labelsize=22)\n",
    "    ax.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "    every_nth_xtick = 4\n",
    "    plt.xticks(np.arange(0, len(x)+1, every_nth_xtick))\n",
    "\n",
    "    if show_total is True and y == 'Cumsum':\n",
    "        ax.axhline(total_num, color='r')\n",
    "        yticks = [*ax.get_yticks(), total_num]\n",
    "        yticklabels = [*ax.get_yticklabels(), int(total_num)]\n",
    "        ax.set_yticks(yticks, labels=yticklabels)\n",
    "    elif  show_total is True and y == 'Precision':\n",
    "        ax.set_ylim(0, 100)\n",
    "\n",
    "    plt.title(ftitle)\n",
    "\n",
    "    # if y == 'Cumsum' and hue != 'Epoch':\n",
    "    #     tmp_figpath = f'{thesis_dirpath}/4_Experiment/shift_fasterrcnn_cumsum'\n",
    "    # elif y == 'Cumsum' and hue == 'Epoch':\n",
    "    #     tmp_figpath = f'{thesis_dirpath}/4_Experiment/shift_fasterrcnn_cumsum_per_epoch'\n",
    "    # elif y == 'Precision' and df['Class'].values[0] == 'all':\n",
    "    #     tmp_figpath = f'{thesis_dirpath}/4_Experiment/shift_fasterrcnn_precision'\n",
    "    # elif y == 'Precision' and df['Class'].values[0] != 'all':\n",
    "    #     tmp_figpath = f'{thesis_dirpath}/4_Experiment/shift_fasterrcnn_precision_perclass'\n",
    "\n",
    "    # plt.savefig(f'{tmp_figpath}/{ftitle}.png', dpi=dpi)\n",
    "    plt.show()\n",
    "\n",
    "#######################################\n",
    "#             one noise pattern, combined epoch with std\n",
    "#######################################\n",
    "# m_names = ['uni20']\n",
    "# m_names = ['ass1']\n",
    "m_names = ['uni20', 'uni10', 'uni5', 'uni1', 'ass20', 'ass10', 'ass5', 'ass1']\n",
    "for m_name in m_names:\n",
    "    print(f'----------------- Noise {m_name} -----------------')\n",
    "    # epos = list(range(1, 9))\n",
    "    # methods = ['CL_SC', 'SC', 'CL_RC','RC', 'LRank', 'CL_NM', 'NM', 'CL_EN', 'EN', 'CL_REN','REN', 'CL_CWE']\n",
    "    methods = ['SC', 'CL_SC', 'NM', 'CL_NM']\n",
    "    # methods = ['SC', 'CL_SC', 'NM', 'CL_NM', 'REN', 'CL_REN', 'EN','CL_EN']\n",
    "    # methods = ['CL_NM']\n",
    "    # methods = ['SC', 'CL_SC', 'NM', 'CL_NM']\n",
    "    # methods = ['CL_SC', 'SC']\n",
    "    # methods = ['CL_RC', 'RC']\n",
    "    # methods = ['CL_EN', 'EN']\n",
    "    # methods = ['CL_REN', 'REN']\n",
    "    # methods = ['CL_NM', 'NM']\n",
    "\n",
    "    topn = 211998\n",
    "    interval = 10000\n",
    "    x = [f'{i+interval}' for i in range(0, topn, interval)]\n",
    "    colnames = [\"Noise\", \"Method\", \"Class\", \"Interval\", \"Cumsum\", \"Sum\", \"Precision\"]\n",
    "    df_cum = pd.DataFrame(columns=colnames)\n",
    "\n",
    "    for method in methods:\n",
    "        # for epo in epos:\n",
    "        tpfp_arr = topn_dic[m_name][method]['all'].values\n",
    "        num_tps, cumsum, precisions = convert_cumsum(tpfp_arr, topn, interval)\n",
    "        data = {\n",
    "            \"Noise\": m_name,\n",
    "            \"Method\": [method]*len(x),\n",
    "            \"Class\": ['all']*len(x),\n",
    "            \"Interval\": x,\n",
    "            \"Cumsum\": cumsum,\n",
    "            \"Sum\": num_tps,\n",
    "            \"Precision\": precisions\n",
    "        }\n",
    "        df_epo = pd.DataFrame(data=data, columns=colnames)\n",
    "        df_cum = pd.concat([df_cum, df_epo], axis=0, ignore_index=True)\n",
    "    # ftitle = f'{m_name}_Top{topn}'\n",
    "    # show_total = True\n",
    "    # # y = 'Cumsum'\n",
    "    # y = 'Precision'\n",
    "    # hue = 'Method'\n",
    "    # # hue = 'Epoch'\n",
    "    # total_num = total_incorrects[m_name]['all']\n",
    "    # draw_precision_segment_cum_std(df_cum, x, total_num, ftitle, topn, interval, y, hue, show_total)\n",
    "    # print('')\n",
    "\n",
    "\n",
    "    topn = 1000\n",
    "    interval = 100\n",
    "    x = [f'{i+interval}' for i in range(0, topn, interval)]\n",
    "    colnames = [\"Method\", \"Class\", \"Interval\", \"Cumsum\", \"Sum\", \"Precision\"]\n",
    "    df_cum = pd.DataFrame(columns=colnames)\n",
    "\n",
    "    for method in methods:\n",
    "        tpfp_arr = topn_dic[m_name][method]['all'].values\n",
    "        num_tps, cumsum, precisions = convert_cumsum(tpfp_arr, topn, interval)\n",
    "        data = {\n",
    "            \"Method\": [method]*len(x),\n",
    "            \"Class\": ['all']*len(x),\n",
    "            \"Interval\": x,\n",
    "            \"Cumsum\": cumsum,\n",
    "            \"Sum\": num_tps,\n",
    "            \"Precision\": precisions\n",
    "        }\n",
    "        df_epo = pd.DataFrame(data=data, columns=colnames)\n",
    "        df_cum = pd.concat([df_cum, df_epo], axis=0, ignore_index=True)\n",
    "    ftitle = f'{m_name}_Top{topn}'\n",
    "    total_num = total_incorrects[m_name]['all']\n",
    "    draw_precision_segment_cum_std(df_cum, x, total_num, ftitle, topn, interval, y, hue, show_total)\n",
    "    print('')\n",
    "\n",
    "# Per class figure\n",
    "# topn = 211998\n",
    "# interval = 10000\n",
    "# # epos = list(range(1, 9))\n",
    "# x = [f'{i+interval}' for i in range(0, topn, interval)]\n",
    "# colnames = [\"Noise\",\"Method\", \"Class\", \"Interval\", \"Cumsum\", \"Sum\", \"Precision\"]\n",
    "# df_cum_byclass_all = pd.DataFrame(columns=colnames)\n",
    "# # m_names = ['uni20', 'uni10', 'uni5', 'uni1', 'ass20', 'ass10', 'ass5', 'ass1']\n",
    "# m_names = ['uni20']\n",
    "# for m_name in m_names:\n",
    "#     for method in methods:\n",
    "#         # for epo in epos:\n",
    "#         for classname in id2class.values():\n",
    "#             tpfp_arr = topn_byclass_dic[m_name][method][classname].values\n",
    "#             num_tps, cumsum, precisions = convert_cumsum(tpfp_arr, topn, interval)\n",
    "#             data = {\n",
    "#                 \"Noise\": m_name,\n",
    "#                 \"Method\": [method]*len(x),\n",
    "#                 \"Class\": [classname]*len(x),\n",
    "#                 \"Interval\": x,\n",
    "#                 \"Cumsum\": cumsum,\n",
    "#                 \"Sum\": num_tps,\n",
    "#                 \"Precision\": precisions\n",
    "#             }\n",
    "#             df_epo = pd.DataFrame(data=data, columns=colnames)\n",
    "#             df_cum_byclass_all = pd.concat([df_cum_byclass_all, df_epo], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "#     show_total = False\n",
    "#     y = 'Precision'\n",
    "#     # y = 'Cumsum'\n",
    "#     hue = 'Method'\n",
    "#     for classname in id2class.values():\n",
    "#         # classname = 'motorcycle'\n",
    "#         ftitle = f'{classname}_{m_name}'\n",
    "#         total_num = total_byclass_incorrects[m_name][classname]\n",
    "#         df_cum_byclass = df_cum_byclass_all.loc[df_cum_byclass_all['Class']==classname, :]\n",
    "#         draw_precision_segment_cum_std(df_cum_byclass, x, total_num, ftitle, topn, interval, y, hue, show_total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save df_cum to latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cum_byclass_all.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concated = pd.concat([df_cum, df_cum_byclass_all], axis=0, ignore_index=True)\n",
    "cond_topall = (df_concated['Interval']=='220000')\n",
    "cond_top1000 = (df_concated['Interval']=='1000')\n",
    "cond_top100 = (df_concated['Interval']=='100')\n",
    "df_concated.loc[cond_topall, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def formating_decimals(df, colnames):\n",
    "\n",
    "    for col in colnames:\n",
    "        df[col] = df[col].apply(lambda x: f'{x:.1f}')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def df_column_switch(df, column1, column2):\n",
    "    i = list(df.columns)\n",
    "    a, b = i.index(column1), i.index(column2)\n",
    "    i[b], i[a] = i[a], i[b]\n",
    "    df = df[i]\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_PK_to_latex(df):\n",
    "\n",
    "    # per class\n",
    "    df = df.drop(columns=[ 'TP_all', 'FP_all', 'TP10', 'FP10', 'TP100', 'FP100', 'TP1000', 'FP1000'], inplace=False)\n",
    "\n",
    "    df = df[ ['Class'] + [ col for col in df.columns if col != 'Class' ] ]\n",
    "\n",
    "    columns = ['Precision', 'Recall', 'P@10', 'P@100', 'P@1000']\n",
    "    df = formating_decimals(df, columns)\n",
    "\n",
    "\n",
    "    method_mapper = {\n",
    "        'CL_NMargin': 'CL_NM',\n",
    "        'CL_SConf': 'CL_SC',\n",
    "        'CL_CWE': 'CL_CWE',\n",
    "        'LRank': 'LRank'\n",
    "    }\n",
    "    df['Method'] = df['Method'].apply(lambda x: method_mapper[x])\n",
    "\n",
    "\n",
    "    MyColumns = pd.MultiIndex.from_tuples([\n",
    "                                        (\"Class\" , \"\"),\n",
    "                                        (\"Method\" , \"\"),\n",
    "                                        (\"\", \"Precision\"),\n",
    "                                        (\"\", \"Recall\"),\n",
    "                                        (\"P at K\", \"P@10\"),\n",
    "                                        (\"P at K\", \"P@100\"),\n",
    "                                        (\"P at K\", \"P@1000\"),\n",
    "                                        ])\n",
    "\n",
    "\n",
    "    # Create new DataFrame with specified Columns, after this you should pass values \n",
    "    df_multi = pd.DataFrame(df , columns = MyColumns)\n",
    "\n",
    "    # a loop for passing values\n",
    "    for item in range(len(MyColumns)):\n",
    "        df_multi.loc[: , MyColumns[item]] = df.iloc[: , item]\n",
    "\n",
    "    sorter = list(id2class.values())\n",
    "\n",
    "    # Original id2class is not sorted by naming..\n",
    "    # df_multi.sort_values(by=\"Class\", key=lambda column: column.map(lambda e: sorter.index(e)), inplace=True)\n",
    "    # df_multi.sort_values(by=\"classname\", axis=0, ascending=True, inplace=True)\n",
    "\n",
    "\n",
    "    # All class\n",
    "    df_multi = df_multi.groupby(by=['Method']).apply(lambda x: x)\n",
    "    # Per-class\n",
    "    # df_multi = df_multi.groupby(by=['Method', 'Class']).apply(lambda x: x.sort_values((\"Epoch\", \"\")))\n",
    "\n",
    "    # print(f'df_multi={df_multi}')\n",
    "    # print(f'df_multi.index={df_multi.index}')\n",
    "    # df_multi = df_multi.droplevel(level=1)\n",
    "    df_multi.reset_index(level=1, inplace=True)\n",
    "\n",
    "    multi_columns = [(\"\", \"Precision\"),\n",
    "                    (\"\", \"Recall\"),\n",
    "                    (\"P at K\", \"P@10\"),\n",
    "                    (\"P at K\", \"P@100\"),\n",
    "                    (\"P at K\", \"P@1000\")]\n",
    "\n",
    "    for i in set(df_multi.index):\n",
    "\n",
    "        for column in multi_columns:\n",
    "            # print(f'i={i}')\n",
    "            # print(f'column={column}')\n",
    "            # print('***')\n",
    "            # print(df_multi.loc[i, column])\n",
    "            number_list = df_multi.loc[i, column].to_numpy(dtype=float)\n",
    "            max_value = number_list.max()\n",
    "            max_rowid = number_list.argmax()\n",
    "            max_cell = \"tttextbf{\" + f'{max_value:.1f}' +'}'\n",
    "\n",
    "            number_list = [f'{i:.1f}' for i in number_list]\n",
    "            number_list[max_rowid] = max_cell\n",
    "\n",
    "            df_multi.loc[i, column] = number_list\n",
    "\n",
    "    \n",
    "    # t2= df_multi.reset_index(level=0, drop=True)\n",
    "    df_multi.drop(columns=[('level_1', '')], inplace=True)\n",
    "\n",
    "    df_multi = df_column_switch(df_multi, (\"Method\" , \"\"), (\"Class\" , \"\"),)\n",
    "\n",
    "    return df_multi\n",
    "\n",
    "\n",
    "# class2shortname = {k: k for k in id2class.values()}\n",
    "# class2shortname['NO_STOPPING_NO_STANDING'] = 'NSNS'\n",
    "# class2shortname['NO_PARKING'] = 'N_PARK'\n",
    "# class2shortname['PASS_EITHER_SIDE'] = 'PESIDE'\n",
    "# class2shortname['PASS_RIGHT_SIDE'] = 'PRSIDE'\n",
    "# class2shortname['PEDESTRIAN_CROSSING'] = 'PCROSS'\n",
    "# class2shortname['PRIORITY_ROAD'] = 'PROAD'\n",
    "\n",
    "latex_dic = {k: None for k in id2class.values()}\n",
    "\n",
    "# m_names1 = ['clean', 'uni1', 'ass1']\n",
    "# m_names2 = ['uni5', 'uni10', 'uni20']\n",
    "# m_names3 = ['ass5', 'ass10', 'ass20']\n",
    "\n",
    "m_names1 = ['uni10', 'uni5', 'uni1']\n",
    "m_names2 = ['ass10', 'ass5', 'ass1']\n",
    "\n",
    "# m_names1 = ['uni20', 'uni10', 'uni5', 'uni1']\n",
    "# m_names2 = ['ass20', 'ass10', 'ass5', 'ass1']\n",
    "\n",
    "for idx, m_name in enumerate(m_names2):\n",
    "    df = cal_byclass_dic[m_name].copy()\n",
    "    df2 = process_PK_to_latex(df)\n",
    "\n",
    "\n",
    "\n",
    "    if idx > 0:\n",
    "        df2.drop(columns=['Class', 'Method'], inplace=True)\n",
    "    \n",
    "    latex_dic[m_name] = df2\n",
    "    # df2.drop(columns=['Class', 'epoch'], inplace=True)\n",
    "\n",
    "\n",
    "final_df = pd.concat(latex_dic, axis=1)\n",
    "\n",
    "def replace_longtable_line(line):\n",
    "    pattern = r'\\\\begin{longtable}{([l]*)}'\n",
    "    replacement = lambda m: '\\\\begin{longtable}{' + 'c' * len(m.group(1)) + '}'\n",
    "    new_line = re.sub(pattern, replacement, line)\n",
    "    return new_line\n",
    "\n",
    "def postprocess_latex(lines, max_epo, col_idx):\n",
    "    lines = lines.replace('tttextbf', '\\\\textbf').replace('\\{','{').replace('\\}','}')\n",
    "\n",
    "    new_lines = []\n",
    "    prev_line = None\n",
    "    \n",
    "    for line in lines.splitlines():\n",
    "        if '\\\\begin{longtable}' in line:\n",
    "            line = replace_longtable_line(line)\n",
    "\n",
    "        if '{r}' in line and 'Continued on next page' not in line:\n",
    "            line = line.replace('{r}', '{c}')\n",
    "\n",
    "        new_lines.append(line)\n",
    "        start_check =False\n",
    "\n",
    "        if prev_line == '\\endlastfoot':\n",
    "            start_check = True\n",
    "\n",
    "        if start_check is False :\n",
    "            # new_lines.append(line)\n",
    "            prev_line = line\n",
    "            continue\n",
    "\n",
    "        if '\\end{longtable}' in line:\n",
    "            continue\n",
    "\n",
    "        if line.split('&')[col_idx] == max_epo:\n",
    "            new_lines.append('\\hline')\n",
    "\n",
    "    return '\\n'.join(new_lines)\n",
    "\n",
    "latex_lines = final_df.to_latex(index=False, escape=True, longtable=True)\n",
    "\n",
    "latex_lines = postprocess_latex(latex_lines, '', 0)\n",
    "\n",
    "# print(latex_lines)\n",
    "with open(f'{tmp_figpath}/latex_table.txt', 'w') as f:\n",
    "    f.write(latex_lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw cumulative plot (deprecated?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# def convert_cumsum(tpfp_list, topn, interval):\n",
    "#     num_tps = []\n",
    "#     precisions = []\n",
    "#     for i in range(0, topn, interval):\n",
    "#         start = i\n",
    "#         end = i + (interval-1)\n",
    "#         if len(tpfp_list[start:end]) == 0:\n",
    "#             num_tp = 0\n",
    "#         else:\n",
    "#             num_tp = sum(tpfp_list[start:end] == 'TP')\n",
    "\n",
    "#             if len(tpfp_list[start:end]) == 0:\n",
    "#                 precision = 0\n",
    "#             else:\n",
    "#                 precision = 100.0*sum(tpfp_list[start:end] == 'TP') / len(tpfp_list[start:end])\n",
    "\n",
    "#         num_tps.append(num_tp)\n",
    "#         precisions.append(precision)\n",
    "\n",
    "#     cumsum = np.cumsum(num_tps)\n",
    "\n",
    "#     return num_tps, cumsum, precisions\n",
    "\n",
    "\n",
    "# def draw_precision_segment_cum_std(df, x, total_num, ftitle, tmp_figpath, topn, interval, y, hue, show_total):\n",
    "#     # if len(df) == 0:\n",
    "#     #     return\n",
    "#     dpi = 50\n",
    "#     fig = plt.figure(dpi=dpi, figsize=(15,8))\n",
    "#     sns.set_theme(style=\"whitegrid\", font=\"serif\")\n",
    "#     sns.set_palette(\"Paired\")\n",
    "#     # plt.style.use(['science','ieee'])\n",
    "    \n",
    "#     linewidth = 5\n",
    "\n",
    "#     if hue == 'Epoch':\n",
    "#         ax = sns.lineplot(x='Interval', y=y, data=df, hue=hue, linewidth=linewidth, legend='full')\n",
    "#     else:\n",
    "#         ax = sns.lineplot(x='Interval', y=y, data=df, hue=hue, linewidth=linewidth, err_style=\"bars\", errorbar=(\"se\", 2))\n",
    "\n",
    "#     leg = ax.legend()\n",
    "#     for i in leg.legendHandles:\n",
    "#         i.set_linewidth(6)\n",
    "\n",
    "#     leg.set_title(hue)\n",
    "#     leg.get_title().set_fontsize('24')\n",
    "#     plt.setp(ax.get_legend().get_texts(), fontsize=24)\n",
    "#     ax.set(xlabel='', ylabel = '')\n",
    "#     ax.tick_params(axis='x', labelsize=26)\n",
    "#     ax.tick_params(axis='y', labelsize=22)\n",
    "\n",
    "#     # if y == 'Precision':\n",
    "#     #     ax.set_ylim(0, 100)\n",
    "\n",
    "#     every_nth_xtick = 4\n",
    "#     plt.xticks(np.arange(0, len(x)+1, every_nth_xtick))\n",
    "\n",
    "#     if show_total is True:\n",
    "#         ax.axhline(total_num, color='r')\n",
    "#         yticks = [*ax.get_yticks(), total_num]\n",
    "#         yticklabels = [*ax.get_yticklabels(), int(total_num)]\n",
    "#         ax.set_yticks(yticks, labels=yticklabels)\n",
    "\n",
    "#     plt.title(ftitle)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     # plt.savefig(f'{tmp_figpath}/{ftitle}.png', dpi=dpi)\n",
    "#     plt.show()\n",
    "\n",
    "# #######################################\n",
    "# #             one noise pattern, combined epoch with std\n",
    "# #######################################\n",
    "# # m_name = 'uni20'\n",
    "# # m_names = ['uni1']\n",
    "# m_names = ['uni20', 'uni10', 'uni5', 'uni1', 'ass20', 'ass10', 'ass5', 'ass1']\n",
    "# # m_names = ['clean_uni1', 'uni1', 'clean_ass1', 'ass1']\n",
    "# # m_names = ['clean', 'clean_uni20', 'uni20','clean_uni1', 'uni1', 'clean_ass20', 'ass20', 'clean_ass1', 'ass1']\n",
    "\n",
    "# for m_name in m_names:\n",
    "\n",
    "#     # methods = ['CL_SC', 'SC', 'CL_RC','RC', 'LRank', 'CL_NM', 'NM', 'CL_EN', 'EN', 'CL_REN','REN', 'CL_CWE']\n",
    "#     # methods = ['SC', 'CL_SC', 'NM', 'CL_NM', 'REN', 'CL_REN', 'EN','CL_EN']\n",
    "#     # methods = ['CL_NM'] # for comparing epoch\n",
    "#     methods = ['SC', 'CL_SC', 'NM', 'CL_NM'] # standard\n",
    "#     # methods = ['CL_SC', 'SC']\n",
    "#     # methods = ['CL_RC', 'RC']\n",
    "#     # methods = ['CL_EN', 'EN']\n",
    "#     # methods = ['CL_REN', 'REN']\n",
    "#     # methods = ['CL_NM', 'NM']\n",
    "\n",
    "#     # tmp_figpath = f'{thesis_dirpath}/4_Experiment/shift_fasterrcnn_cumsum'\n",
    "#     # tmp_figpath = f'{thesis_dirpath}/4_Experiment/shift_fasterrcnn_cumsum_per_epoch'\n",
    "#     # tmp_figpath = f'{thesis_dirpath}/4_Experiment/shift_fasterrcnn_precision_per_epoch'\n",
    "#     # tmp_figpath = f'{thesis_dirpath}/4_Experiment/shift_fasterrcnn_precision'\n",
    "#     # tmp_figpath = f'{thesis_dirpath}/4_Experiment/shift_fasterrcnn_precision_flex'\n",
    "#     # tmp_figpath = f'{thesis_dirpath}/4_Experiment/shift_fasterrcnn_cumsum_perclass'\n",
    "#     # tmp_figpath = f'{thesis_dirpath}/4_Experiment/shift_fasterrcnn_precision_perclass'\n",
    "#     tmp_figpath = ''\n",
    "\n",
    "\n",
    "#     topn = 20000\n",
    "#     interval = 2000\n",
    "#     x = [f'{i+interval}' for i in range(0, topn, interval)]\n",
    "#     colnames = [\"Method\", \"Class\", \"Interval\", \"Cumsum\", \"Sum\", \"Precision\"]\n",
    "#     df_cum = pd.DataFrame(columns=colnames)\n",
    "\n",
    "#     for method in methods:\n",
    "#         tpfp_arr = topn_dic[m_name][method]['all'].values\n",
    "#         num_tps, cumsum, precisions = convert_cumsum(tpfp_arr, topn, interval)\n",
    "#         data = {\n",
    "#             \"Method\": [method]*len(x),\n",
    "#             \"Class\": ['all']*len(x),\n",
    "#             \"Interval\": x,\n",
    "#             \"Cumsum\": cumsum,\n",
    "#             \"Sum\": num_tps,\n",
    "#             \"Precision\": precisions\n",
    "#         }\n",
    "#         df_epo = pd.DataFrame(data=data, columns=colnames)\n",
    "#         df_cum = pd.concat([df_cum, df_epo], axis=0, ignore_index=True)\n",
    "\n",
    "#     ftitle = f'{m_name}_Top{topn}'\n",
    "#     show_total = False\n",
    "#     # y = 'Cumsum'\n",
    "#     y = 'Precision'\n",
    "#     hue = 'Method'\n",
    "#     # hue = 'Epoch'\n",
    "#     total_num = total_incorrects[m_name]['all']\n",
    "#     draw_precision_segment_cum_std(df_cum, x, total_num, ftitle, tmp_figpath, topn, interval, y, hue, show_total)\n",
    "#     print('')\n",
    "\n",
    "\n",
    "#     # topn = 2000\n",
    "#     # interval = 200\n",
    "#     # x = [f'{i+interval}' for i in range(0, topn, interval)]\n",
    "#     # colnames = [\"Method\", \"Class\", \"Interval\", \"Cumsum\", \"Sum\", \"Precision\"]\n",
    "#     # df_cum = pd.DataFrame(columns=colnames)\n",
    "\n",
    "#     # for method in methods:\n",
    "\n",
    "#     #     tpfp_arr = topn_dic[m_name][method]['all'].values\n",
    "#     #     num_tps, cumsum, precisions = convert_cumsum(tpfp_arr, topn, interval)\n",
    "#     #     data = {\n",
    "#     #         \"Method\": [method]*len(x),\n",
    "#     #         \"Class\": ['all']*len(x),\n",
    "#     #         \"Interval\": x,\n",
    "#     #         \"Cumsum\": cumsum,\n",
    "#     #         \"Sum\": num_tps,\n",
    "#     #         \"Precision\": precisions\n",
    "#     #     }\n",
    "#     #     df_epo = pd.DataFrame(data=data, columns=colnames)\n",
    "#     #     df_cum = pd.concat([df_cum, df_epo], axis=0, ignore_index=True)\n",
    "#     # ftitle = f'{m_name}_Top{topn}'\n",
    "#     # total_num = total_incorrects[m_name]['all']\n",
    "#     # draw_precision_segment_cum_std(df_cum, x, total_num, ftitle, tmp_figpath, topn, interval, y, hue, show_total)\n",
    "#     # print('')\n",
    "\n",
    "# #############################\n",
    "# #                  Per class figure\n",
    "# #############################\n",
    "\n",
    "# # topn = 5000\n",
    "# # interval = 500\n",
    "# # # epos = list(range(1, 9))\n",
    "# # epos = [1]\n",
    "# # x = [f'{i+interval}' for i in range(0, topn, interval)]\n",
    "# # colnames = [\"Model\", \"Epoch\", \"Method\", \"Class\", \"Interval\", \"Cumsum\", \"Sum\", \"Precision\"]\n",
    "# # df_cum = pd.DataFrame(columns=colnames)\n",
    "# # # m_names = ['uni20', 'uni10', 'uni5', 'uni1', 'ass20', 'ass10', 'ass5', 'ass1']\n",
    "# # m_names = ['ass1']\n",
    "# # for m_name in m_names:\n",
    "# #     for method in methods:\n",
    "# #         for epo in epos:\n",
    "# #             for classname in id2class.values():\n",
    "# #                 tpfp_arr = topn_byclass_dic[m_name][epo][method][classname].values\n",
    "# #                 num_tps, cumsum, precisions = convert_cumsum(tpfp_arr, topn, interval)\n",
    "# #                 data = {\n",
    "# #                     \"Model\": m_name,\n",
    "# #                     \"Epoch\": epo,\n",
    "# #                     \"Method\": [method]*len(x),\n",
    "# #                     \"Class\": [classname]*len(x),\n",
    "# #                     \"Interval\": x,\n",
    "# #                     \"Cumsum\": cumsum,\n",
    "# #                     \"Sum\": num_tps,\n",
    "# #                     \"Precision\": precisions\n",
    "# #                 }\n",
    "# #                 df_epo = pd.DataFrame(data=data, columns=colnames)\n",
    "\n",
    "# #                 # print(f'Processing {m_name} {classname} {method} epoch {epo}')\n",
    "# #                 # if m_name == 'ass1' and epo == 1 and method == 'CL_SC' and classname == 'car':\n",
    "# #                 #     print('Happened Once')\n",
    "\n",
    "# #                 df_cum = pd.concat([df_cum, df_epo], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "# # show_total = False\n",
    "# # y = 'Precision'\n",
    "# # # y = 'Cumsum'\n",
    "# # hue = 'Method'\n",
    "# # for m_name in m_names:\n",
    "# #     for classname in id2class.values():\n",
    "# #         # classname = 'motorcycle'\n",
    "# #         ftitle = f'{classname}_{m_name}'\n",
    "# #         total_num = total_byclass_incorrects[m_name][classname]\n",
    "# #         df_cum_byclass = df_cum.loc[(df_cum['Model']==m_name)&(df_cum['Class']==classname)&(df_cum['Epoch']==1), :]\n",
    "# #         # df_cum_byclass = df_cum.loc[df_cum['Class']==classname, :]\n",
    "# #         draw_precision_segment_cum_std(df_cum_byclass, x, total_num, ftitle, tmp_figpath, topn, interval, y, hue, show_total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AED Percentage/Cumsum stacked bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def draw_stacked_bar(df, ftitle, datatype):\n",
    "    # Compute count of each class within each interval\n",
    "    count_df = df.groupby(['Interval', 'labels_gt_des']).size().reset_index(name='count')\n",
    "    \n",
    "    # Check if we need percentage or cumulative sum\n",
    "    if datatype == 'percent':\n",
    "        # Compute the total for each interval\n",
    "        total = count_df.groupby('Interval')['count'].transform('sum')\n",
    "        # Compute the percentage\n",
    "        count_df['value'] = 100 * (count_df['count'] / total)\n",
    "\n",
    "    elif datatype == 'cumsum':\n",
    "        # Compute the cumulative sum\n",
    "        count_df['value'] = count_df.groupby('labels_gt_des')['count'].cumsum()\n",
    "\n",
    "    # elif datatype == 'precision':\n",
    "    #     # Compute the total for each interval\n",
    "    #     total = count_df.groupby('Interval')['count'].transform('sum')\n",
    "    #     # Compute the percentage\n",
    "    #     count_df['value'] = 100 * (count_df['count'] / total)\n",
    "\n",
    "\n",
    "    # Pivot the dataframe to make it suitable for stacked barplot\n",
    "    pivoted_df = count_df.pivot(index='Interval', columns='labels_gt_des', values='value').reset_index()\n",
    "    pivoted_df.fillna(0, inplace=True)  # Fill missing classes with 0\n",
    "\n",
    "    # Define a color mapping for classes\n",
    "    colors = sns.color_palette(\"tab10\", len(id2class.items()))\n",
    "    class_colors = {k: colors[i] for i, k in id2class.items()}\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Track bottom values for stacked bars\n",
    "    bottoms = {interval: 0 for interval in pivoted_df['Interval']}\n",
    "\n",
    "    # Dynamically stack bars based on unique labels and use predefined colors\n",
    "    for label in count_df['labels_gt_des'].unique():\n",
    "        sns.barplot(x='Interval', y=label, data=pivoted_df, label=label, \n",
    "                    bottom=[bottoms[interval] for interval in pivoted_df['Interval']], color=class_colors[label])\n",
    "        \n",
    "        # Update the bottom values for the next class\n",
    "        for interval in pivoted_df['Interval']:\n",
    "            bottoms[interval] += pivoted_df.loc[pivoted_df['Interval'] == interval, label].values[0]\n",
    "\n",
    "    ylabel = 'Percentage' if datatype else 'Cumulative Sum'\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel('Interval')\n",
    "    ax.legend(title=\"Class\", loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    ax.set_title(ftitle)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "####################################\n",
    "# m_names = ['clean', 'clean_uni20', 'uni20','clean_uni1', 'uni1', 'clean_ass20', 'ass20', 'clean_ass1', 'ass1']\n",
    "# m_names = ['uni20', 'uni10', 'uni5', 'uni1', 'ass20', 'ass10', 'ass5', 'ass1']\n",
    "m_names = ['ass10']\n",
    "# m_names = ['clean', 'clean_uni1', 'uni1', 'clean_ass1', 'ass1']\n",
    "# m_names = ['clean', 'clean_uni1', 'uni1', 'clean_ass1', 'ass1']\n",
    "# m_names = ['clean_ass1', 'ass1']\n",
    "methods = ['SC']\n",
    "# epos = [1]\n",
    "# epos = list(range(1, 9))\n",
    "\n",
    "topn = 1000\n",
    "num_intervals = 10\n",
    "# x = [f'{i+interval}' for i in range(0, topn, interval)]\n",
    "# colnames = [\"Model\", \"Method\", \"Epoch\", \"Class\", \"Interval\", \"Cumsum\", \"Sum\", \"Precision\"]\n",
    "# df_cum = pd.DataFrame(columns=colnames)\n",
    "\n",
    "for m_name in m_names:\n",
    "    for method in methods:\n",
    "            dic = {\n",
    "                'true_labels_des': topn_dic[m_name][method]['true_labels_des'][:topn],\n",
    "                'labels_gt_des': topn_dic[m_name][method]['labels_gt_des'][:topn]\n",
    "            }\n",
    "            \n",
    "            # Example data\n",
    "            # topn = 1000  # Define your desired value for topn\n",
    "            # dic = {\n",
    "            #     'labels_gt_des': (['car']*3+['truck']*2+['bus']*5)*10,\n",
    "            # }\n",
    "            # Create dataframe\n",
    "            df = pd.DataFrame(dic)\n",
    "\n",
    "            # Cap the dataframe to the first topn rows\n",
    "            # df = df.head(topn)\n",
    "\n",
    "            # Create a dynamic 'Interval' column\n",
    "            interval_size = topn // num_intervals\n",
    "            df['Interval'] = np.repeat(np.arange(1, num_intervals+1) * interval_size, interval_size)\n",
    "\n",
    "            ftitle = f'{m_name} / {method} / Top{topn}'\n",
    "            # draw_stacked_bar(df, ftitle, datatype='cumsum')\n",
    "            draw_stacked_bar(df, ftitle, datatype='percent')\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look into details (stacked bar with precision)\n",
    "# AED Performance: P@K, R@K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topn_dic = aed_topn['all']\n",
    "# total_incorrects = aed_topn['all_incorrect']\n",
    "# topn_byclass_dic = aed_topn['byclass']\n",
    "# total_byclass_incorrects = aed_topn['byclass_incorrect']\n",
    "# topn_byclass_dic['uni10']['CL_SC']['car'][-10:]\n",
    "topn_dic['uni10']['CL_SC']['all'][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "\n",
    "def get_sorted_idxes_and_c_incorrect(df, classname, colname, is_remove):\n",
    "\n",
    "    li = []\n",
    "\n",
    "    if classname == 'all':\n",
    "        class_df = df.copy()\n",
    "    else:\n",
    "        class_df = df.loc[df['label_gt_des']==classname]\n",
    "    \n",
    "    if colname[:3] == 'CL_':\n",
    "        if is_remove is True:\n",
    "            class_df = df.loc[df[colname] != 999999]\n",
    "        class_df = class_df.sort_values(by=colname, ascending=True)\n",
    "\n",
    "        # li is always cut by 999999\n",
    "        li = df.loc[df[colname] != 999999].index.values\n",
    "\n",
    "    elif colname in ['NM', 'SC', 'EN']:\n",
    "        class_df = class_df.sort_values(by=colname, ascending=True, inplace=False)\n",
    "        li = class_df.index.values\n",
    "        \n",
    "    elif colname in ['REN', 'RC']:\n",
    "        class_df = class_df.sort_values(by=colname, ascending=False, inplace=False)\n",
    "        li = class_df.index.values\n",
    "\n",
    "    value_count = class_df['c_incorrect'].value_counts()\n",
    "\n",
    "    # if True not in value_count.index:\n",
    "\n",
    "\n",
    "    total_c_incorrect = class_df['c_incorrect'].value_counts()[True]\n",
    "    total_c_correct = class_df['c_incorrect'].value_counts()[False]\n",
    "\n",
    "    return li, class_df, total_c_incorrect, total_c_correct\n",
    "\n",
    "\n",
    "def process_interval_counts_per_class(df, figdir, img_prefix, classname):\n",
    "\n",
    "    if 'precision_true_perclass' in figdir:\n",
    "        legend_label_des = 'true_label_des'\n",
    "    else:\n",
    "        legend_label_des = 'label_pred_des'\n",
    "\n",
    "    grouped_df = df.groupby(['Interval', 'label_gt_des', legend_label_des]).size().reset_index(name='count')\n",
    "\n",
    "    # grouped_df = df.groupby(['Interval', 'label_gt_des', legend_label_des]).size()\n",
    "    # grouped_df = grouped_df.unstack(fill_value=0).stack().reset_index(name='count')\n",
    "\n",
    "    # Compute precision\n",
    "    total_for_label = grouped_df.groupby(['Interval', 'label_gt_des'])['count'].sum(min_count=1).reset_index(name='total_for_label')\n",
    "\n",
    "    if legend_label_des == 'true_label_des':\n",
    "        correct_preds = grouped_df[grouped_df['label_gt_des'] != grouped_df[legend_label_des]]\n",
    "    elif legend_label_des == 'label_pred_des':\n",
    "        correct_preds = grouped_df[grouped_df['label_gt_des'] == grouped_df[legend_label_des]]\n",
    "\n",
    "    true_positive = correct_preds.groupby(['Interval', 'label_gt_des'])['count'].sum(min_count=1).reset_index(name='true_positive')\n",
    "    precision_df = pd.merge(total_for_label, true_positive, on=['Interval', 'label_gt_des'], how='left').fillna(0)\n",
    "    precision_df['precision'] = precision_df['true_positive'] / precision_df['total_for_label']\n",
    "\n",
    "    pivoted_df = grouped_df.pivot_table(index=['Interval', 'label_gt_des'], columns=legend_label_des, values='count', fill_value=0, aggfunc=lambda x: x.sum(min_count=1)).unstack().fillna(0).stack().reset_index()\n",
    "\n",
    "    # pivoted_df = grouped_df.pivot_table(index=['Interval', 'label_gt_des'], columns=legend_label_des, values='count', fill_value=0, aggfunc='count').unstack().rename(columns={0:'count'}).reset_index()\n",
    "\n",
    "    unique_labels = id2class.values()\n",
    "    true_labels = id2class.values()\n",
    "\n",
    "    colors = sns.color_palette(\"tab10\", len(id2class.items()))\n",
    "    class_colors = {i: colors[i] for i, k in id2class.items()}\n",
    "\n",
    "    for label in unique_labels:\n",
    "\n",
    "        if classname != 'all' and label != classname:\n",
    "            continue\n",
    "\n",
    "        data = pivoted_df[pivoted_df['label_gt_des'] == label].copy()\n",
    "        precision_data = precision_df[precision_df['label_gt_des'] == label]\n",
    "\n",
    "        # Ensure data contains columns for all true_labels\n",
    "        for true_label in true_labels:\n",
    "            if true_label not in data:\n",
    "                data[true_label] = 0\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        # Plotting the bars with increased width\n",
    "        print(f'len of df = {len(df)}')\n",
    "        if len(df) >= 110000:\n",
    "            bar_width = 2000\n",
    "        elif len(df) >= 10000:\n",
    "            bar_width = 200\n",
    "        elif len(df) >= 4000:\n",
    "            bar_width = 100\n",
    "        elif len(df) >= 1000:\n",
    "            bar_width = 70\n",
    "        else:\n",
    "            bar_width = 20\n",
    "\n",
    "        bottom_data = [0] * len(data)\n",
    "\n",
    "        for idx, true_label in enumerate(true_labels):\n",
    "            ax.bar(data['Interval'], data[true_label], bottom=bottom_data, label=true_label, color=class_colors[idx], width=bar_width)\n",
    "            # ax.bar(data['Interval'], data[true_label], bottom=bottom_data, label=true_label, color=colors[idx], width=bar_width)\n",
    "            bottom_data = [i+j for i,j in zip(bottom_data, data[true_label].tolist())]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # Twin the y-axis for the line plot\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.set_ylim(0, 1)\n",
    "        sns.lineplot(x='Interval', y='precision', data=precision_data, ax=ax2, color='black', marker='o', label='Precision')\n",
    "        ax2.set_ylabel('Precision')\n",
    "\n",
    "        # Combining legends from both axes\n",
    "        lines, labels = ax.get_legend_handles_labels()\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "\n",
    "        plt.setp(ax2.get_legend().get_texts(), fontsize=16)\n",
    "        ax.set(xlabel='', ylabel = '')\n",
    "        ax2.set(xlabel='', ylabel = '')\n",
    "        ax.tick_params(axis='x', labelsize=26)\n",
    "        ax.tick_params(axis='y', labelsize=22)\n",
    "        ax2.tick_params(axis='y', labelsize=22)\n",
    "\n",
    "        # ax2.get_legend().set_visible(False)\n",
    "\n",
    "        if max(bottom_data) <= 10:\n",
    "            ax.yaxis.set_major_locator(ticker.MultipleLocator(base=1))\n",
    "        elif max(bottom_data) <= 20:\n",
    "            ax.yaxis.set_major_locator(ticker.MultipleLocator(base=2))\n",
    "        elif max(bottom_data) <= 50:\n",
    "            ax.yaxis.set_major_locator(ticker.MultipleLocator(base=5))\n",
    "        elif max(bottom_data) <= 100:\n",
    "            ax.yaxis.set_major_locator(ticker.MultipleLocator(base=10))\n",
    "        elif max(bottom_data) <= 200:\n",
    "            ax.yaxis.set_major_locator(ticker.MultipleLocator(base=20))\n",
    "        elif max(bottom_data) <= 300:\n",
    "            ax.yaxis.set_major_locator(ticker.MultipleLocator(base=30))\n",
    "        elif max(bottom_data) >= 1000:\n",
    "            ax.yaxis.set_major_locator(ticker.MultipleLocator(base=50))\n",
    "        elif max(bottom_data) >= 10000:\n",
    "            ax.yaxis.set_major_locator(ticker.MultipleLocator(base=500))\n",
    "        else:\n",
    "            ax.yaxis.set_major_locator(ticker.MultipleLocator(base=40))\n",
    "\n",
    "\n",
    "        # Do not use it for thesis\n",
    "        # ax.set_ylabel('Count')\n",
    "        # ax.set_xlabel('Interval')\n",
    "        # ax.set_title(f\"Class: {label}\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        # plt.savefig(f'{figdir}/{img_prefix}_{label}.png', dpi=50)\n",
    "        # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_interval_precision(df, tmp_figpath, grouped_filepath, yaxis, topn, cut_by_confident_joint, total_c_incorrect, show_total):\n",
    "    \n",
    "    if yaxis == 'Precision':\n",
    "        ############## Segmented Precision ##############\n",
    "        # Group by 'Interval' and 'label_gt_des' and compute the sum of 'correct' and count of 'label_gt_des'\n",
    "        grouped_df = df.groupby(['Interval', 'label_gt_des']).agg(total=('label_gt_des', 'size'), incorrect_sum=('c_incorrect', 'sum')).reset_index()\n",
    "\n",
    "        # Calculate precision\n",
    "        grouped_df['precision'] = grouped_df['incorrect_sum'] / grouped_df['total']\n",
    "\n",
    "        ############## Precision at K ##############\n",
    "    elif yaxis in ['patk', 'ratk', 'patk_all',  'ratk_all']:\n",
    "\n",
    "        df['is_TP'] = (df['aed_tpfp'] == 'TP').astype(int)\n",
    "        df['is_FP'] = (df['aed_tpfp'] == 'FP').astype(int)  \n",
    "        df['is_TN'] = (df['aed_tpfp'] == 'TN').astype(int)  \n",
    "        df['is_FN'] = (df['aed_tpfp'] == 'FN').astype(int)  \n",
    "\n",
    "        if yaxis == 'patk':\n",
    "            # Compute cumulative sum of TP and FP based on sorted intervals\n",
    "            df = df.sort_values(by=['label_gt_des', 'Interval'])\n",
    "            df['tp_cumsum'] = df.groupby(['label_gt_des'])['is_TP'].cumsum()\n",
    "            df['fp_cumsum'] = df.groupby(['label_gt_des'])['is_FP'].cumsum()\n",
    "\n",
    "            # Get the aggregated TP and FP at each unique interval\n",
    "            grouped_df = df[df['Interval'].isin(df['Interval'].unique())].copy()\n",
    "            grouped_df['total'] = grouped_df.groupby(['label_gt_des'])['Interval'].cumcount() + 1\n",
    "            grouped_df['tp_sum'] = grouped_df['tp_cumsum']\n",
    "            grouped_df['fp_sum'] = grouped_df['fp_cumsum']\n",
    "\n",
    "            grouped_df['patk'] = grouped_df['tp_sum'] / (grouped_df['tp_sum'] + grouped_df['fp_sum'])\n",
    "            grouped_df = grouped_df[['label_gt_des', 'Interval', 'total', 'tp_sum', 'fp_sum', 'patk']].reset_index(drop=True)\n",
    "\n",
    "        elif yaxis == 'ratk':\n",
    "\n",
    "            # Compute cumulative sum of TP based on sorted intervals\n",
    "            df = df.sort_values(by=['label_gt_des', 'Interval', 'Epoch'])\n",
    "            df['tp_cumsum'] = df.groupby(['label_gt_des', 'Epoch'])['is_TP'].cumsum()\n",
    "\n",
    "            # Get the aggregated TP at each unique interval\n",
    "            grouped_df = df[df['Interval'].isin(df['Interval'].unique())].copy()\n",
    "            grouped_df['tp_sum'] = grouped_df['tp_cumsum']\n",
    "\n",
    "            # Total relevant items for a class = TP + FN\n",
    "            total_relevant = df.groupby(['label_gt_des', 'Epoch']).agg(total_relevant=('aed_tpfp', lambda x: (x == 'TP').sum() + (x == 'FN').sum())).reset_index()\n",
    "\n",
    "            # Merge the relevant count to our grouped_df\n",
    "            grouped_df = pd.merge(grouped_df, total_relevant, on=['label_gt_des', 'Epoch'], how='left')\n",
    "\n",
    "            # Calculate recall at k\n",
    "            grouped_df['ratk'] = grouped_df['tp_sum'] / grouped_df['total_relevant']\n",
    "            grouped_df = grouped_df[['label_gt_des', 'Epoch', 'Interval', 'tp_sum', 'total_relevant', 'ratk']].reset_index(drop=True)\n",
    "        \n",
    "        elif yaxis == 'patk_all':\n",
    "            # Compute cumulative sum of TP and FP based on sorted intervals\n",
    "            df = df.sort_values(by=['Method', 'Interval', 'Epoch'])\n",
    "            df['tp_cumsum'] = df.groupby(['Method', 'Epoch'])['is_TP'].cumsum()\n",
    "            df['fp_cumsum'] = df.groupby(['Method', 'Epoch'])['is_FP'].cumsum()\n",
    "\n",
    "            # Get the aggregated TP and FP at each unique interval\n",
    "            grouped_df = df[df['Interval'].isin(df['Interval'].unique())].copy()\n",
    "            grouped_df['total'] = grouped_df.groupby(['Method', 'Epoch'])['Interval'].cumcount() + 1\n",
    "            grouped_df['tp_sum'] = grouped_df['tp_cumsum']\n",
    "            grouped_df['fp_sum'] = grouped_df['fp_cumsum']\n",
    "\n",
    "            grouped_df[yaxis] = grouped_df['tp_sum'] / (grouped_df['tp_sum'] + grouped_df['fp_sum'])\n",
    "            grouped_df = grouped_df[['Method', 'Epoch', 'Interval', 'total', 'tp_sum', 'fp_sum', 'confident_joint_thresh', yaxis]].reset_index(drop=True)\n",
    "\n",
    "        elif yaxis ==  'ratk_all':\n",
    "            # Compute cumulative sum of TP based on sorted intervals\n",
    "            df = df.sort_values(by=['Method', 'Interval', 'Epoch'])\n",
    "            df['tp_cumsum'] = df.groupby(['Method', 'Epoch'])['is_TP'].cumsum()\n",
    "\n",
    "            # Get the aggregated TP at each unique interval\n",
    "            grouped_df = df[df['Interval'].isin(df['Interval'].unique())].copy()\n",
    "            grouped_df['tp_sum'] = grouped_df['tp_cumsum']\n",
    "\n",
    "            # Total relevant items for a class = TP + FN\n",
    "            total_relevant = df.groupby(['Method','Epoch']).agg(total_relevant=('aed_tpfp', lambda x: (x == 'TP').sum() + (x == 'FN').sum())).reset_index()\n",
    "\n",
    "            # No longer stands forrandom rounds\n",
    "            # assert total_relevant['total_relevant'].unique() == total_c_incorrect\n",
    "\n",
    "            # Merge the relevant count to our grouped_df\n",
    "            grouped_df = pd.merge(grouped_df, total_relevant, on=['Method', 'Epoch'], how='left')\n",
    "\n",
    "            # Calculate recall at k\n",
    "            grouped_df[yaxis] = grouped_df['tp_sum'] / grouped_df['total_relevant']\n",
    "            grouped_df = grouped_df[['Method', 'Epoch', 'Interval', 'tp_sum', 'total_relevant', 'confident_joint_thresh', yaxis]].reset_index(drop=True)\n",
    "\n",
    "    # if grouped_df_path is not None:\n",
    "    #     grouped_df =pd.read_csv(grouped_df_path, index=False)\n",
    "    # else:   \n",
    "    #     grouped_df.to_csv(f'{grouped_filepath}', index=False)\n",
    "\n",
    "\n",
    "    ##########################################\n",
    "    # Hard-coded the colors for each class --> align with the shift classes\n",
    "    # dict_values(['pedestrian', 'car', 'truck', 'bus', 'motorcycle', 'bicycle'])\n",
    "\n",
    "    shiftall_class_order = ['person', 'car', 'truck', 'bus', 'motorcycle', 'bicycle']\n",
    "    \n",
    "    if yaxis in ['Precision', 'patk', 'ratk']:\n",
    "        colors = sns.color_palette(\"tab10\", len(id2class.items()))\n",
    "        class_colors = {k: colors[i] for i, k in enumerate(shiftall_class_order)}\n",
    "        hue_order =shiftall_class_order\n",
    "    elif yaxis in [ 'patk_all', 'ratk_all']:\n",
    "        # methods = df['method'].unique()\n",
    "        methods = ['SC', 'CL_SC', 'NM', 'CL_NM']\n",
    "        print(f'methods={methods}')\n",
    "        sns.set_palette(\"Paired\")\n",
    "        colors = sns.color_palette(\"Paired\", len(methods))\n",
    "        class_colors = {k: colors[i] for i, k in enumerate(methods)}\n",
    "        # print(f'class_colors={class_colors}')\n",
    "        hue_order = methods\n",
    "\n",
    "    grouped_df = grouped_df.loc[grouped_df['Interval'] <= topn+1]\n",
    "\n",
    "    #######################################\n",
    "    #              Cut the dataframe by confident joint                 #\n",
    "    #######################################\n",
    "    if cut_by_confident_joint is True:\n",
    "        #  cut all methods by the same confident joint\n",
    "        grouped_df = grouped_df.loc[grouped_df['Interval'] <= grouped_df['confident_joint_thresh']]\n",
    "\n",
    "        topn = round(grouped_df['confident_joint_thresh'].mean())\n",
    "        print(f'Cut by confident joint, average topn={topn}')\n",
    "    else:\n",
    "        #  cut only CL_ methods by the confident joint\n",
    "        # conds = (grouped_df['Method']=='CL_SC') | (grouped_df['Method']=='CL_NM')\n",
    "        cut_CL_SC_conds = (grouped_df['Method']=='CL_SC') & (grouped_df['Interval'] <= grouped_df['confident_joint_thresh'])\n",
    "        cut_CL_NM_conds = (grouped_df['Method']=='CL_NM') & (grouped_df['Interval'] <= grouped_df['confident_joint_thresh'])\n",
    "        other_conds = (grouped_df['Method']=='SC') | (grouped_df['Method']=='NM')\n",
    "\n",
    "        cut_CL_SC = grouped_df.loc[cut_CL_SC_conds] \n",
    "        cut_CL_NM = grouped_df.loc[cut_CL_NM_conds] \n",
    "        other_df = grouped_df.loc[other_conds] \n",
    "\n",
    "        grouped_df = pd.concat([cut_CL_SC, cut_CL_NM, other_df])\n",
    "\n",
    "        topn = topn\n",
    "\n",
    "    ###########################################\n",
    "    #                          Tranform Interval to percentage\n",
    "    ###########################################\n",
    "    grouped_df['Interval_percent'] = grouped_df['Interval'] / (1.0*topn)\n",
    "    xaxis= 'Interval'\n",
    "    # xaxis= 'Interval_percent'\n",
    "\n",
    "    # Plotting\n",
    "    if yaxis == 'Precision':\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = sns.lineplot(data=grouped_df, x=\"Interval\", y=\"precision\", hue=\"label_gt_des\", hue_order=hue_order, marker=\"o\", linestyle='dotted', palette=class_colors, markersize=20, linewidth=5) \n",
    "        # ax.set_ylim(-0.05,1)\n",
    "    elif yaxis in ['patk', 'ratk']:\n",
    "        # dot style\n",
    "        # ax = sns.lineplot(data=grouped_df, x=\"Interval\", y=yaxis, hue=\"label_gt_des\", hue_order=hue_order, marker=\"o\", linestyle='dotted', palette=class_colors, markersize=5, linewidth=1) \n",
    "        # solid line\n",
    "        ax = sns.lineplot(data=grouped_df, x=\"Interval\", y=yaxis, hue=\"label_gt_des\", hue_order=hue_order, palette=class_colors, markersize=5, linewidth=2) \n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_xlim(xmin=0, xmax=topn)\n",
    "        ################### Area under Curve ###################\n",
    "        # Compute AUC for each class\n",
    "        auc_results = {}\n",
    "        unique_classes = grouped_df['label_gt_des'].unique()\n",
    "\n",
    "        for label in unique_classes:\n",
    "            class_df = grouped_df[grouped_df['label_gt_des'] == label].sort_values(by='Interval')\n",
    "            auc = np.trapz(class_df[yaxis], class_df['Interval'])\n",
    "            # Normalize AUC by dividing it with the maximum possible AUC\n",
    "            auc_results[label] = auc / (1.0*topn)\n",
    "\n",
    "        print('AUC Results')\n",
    "        pp.pprint(auc_results)\n",
    "        ###################################################\n",
    "    elif yaxis in ['patk_all' ,'ratk_all']:\n",
    "        ax = sns.lineplot(data=grouped_df, x=xaxis, y=yaxis,  hue=\"Method\", markersize=1, linewidth=5,hue_order=hue_order, palette=class_colors, errorbar='sd', err_style='bars',err_kws={'errorevery': int(topn/5)})\n",
    "        ax.set_ylim(0,1)\n",
    "        # ax.set_ylim(auto=True)\n",
    "\n",
    "        if xaxis == 'Interval_percent':\n",
    "            ax.set_xlim(xmin=0, xmax=1)\n",
    "        elif xaxis == 'Interval':\n",
    "            ax.set_xlim(xmin=0, xmax=topn)\n",
    "        # ax.axis('off')\n",
    "\n",
    "        # ax.set_ylim(ymin=-0.005, ymax=1.005)\n",
    "        # labels = ax.get_yticklabels()\n",
    "        # # remove the first and the last labels\n",
    "        # labels[0] = labels[-1] = \"\"\n",
    "        # ax.set_yticklabels(labels)\n",
    "\n",
    "        ################### Area under Curve ###################\n",
    "        # Compute AUC for each class\n",
    "        unique_methods = grouped_df['Method'].unique()\n",
    "        auc_results = {k: {} for k in unique_methods}\n",
    "\n",
    "        if m_name == 'ass1':\n",
    "            print('')\n",
    "\n",
    "        for method in unique_methods:\n",
    "            epo_aucs = []\n",
    "            epo_cf_threshs = []\n",
    "            if m_name == 'uni1':\n",
    "                print('')\n",
    "            for epo in epos:\n",
    "                epo_df = grouped_df.loc[(grouped_df['Method']==method)&(grouped_df['Epoch']==epo)].sort_values(by='Interval')\n",
    "                auc = np.trapz(epo_df[yaxis], epo_df['Interval'])\n",
    "\n",
    "                confident_joint_thresh = epo_df['confident_joint_thresh'].unique()\n",
    "\n",
    "                assert confident_joint_thresh.shape[0] == 1\n",
    "\n",
    "                confident_joint_thresh = confident_joint_thresh[0]\n",
    "\n",
    "                if cut_by_confident_joint is True:\n",
    "                    epo_cf_threshs.append(confident_joint_thresh)\n",
    "                    auc = auc/(1.0*confident_joint_thresh)\n",
    "                    epo_aucs.append(auc)\n",
    "\n",
    "                else:\n",
    "                    # topn should adopted to those confident joint < topn\n",
    "                    if confident_joint_thresh < topn and method[:3] == 'CL_':\n",
    "                        auc = auc/(1.0*confident_joint_thresh)\n",
    "                    else:\n",
    "                        auc = auc/(1.0*topn)\n",
    "                    epo_aucs.append(auc)\n",
    "\n",
    "            # Normalize AUC by dividing it with the maximum possible AUC\n",
    "            if cut_by_confident_joint is True:\n",
    "                auc_dic = {'avg': np.average(epo_aucs),\n",
    "                                    'std': np.std(epo_aucs, ddof=1),\n",
    "                                    'aucs': epo_aucs,\n",
    "                                    'thresh_avg': np.average(epo_cf_threshs),\n",
    "                                    'thresh_std': np.std(epo_cf_threshs, ddof=1),\n",
    "                                    'thresh_aucs': epo_cf_threshs,\n",
    "                                    }\n",
    "            else:\n",
    "                auc_dic = {'avg': np.average(epo_aucs),\n",
    "                                    'std': np.std(epo_aucs, ddof=1),\n",
    "                                    'aucs': epo_aucs\n",
    "                                    }\n",
    "            auc_results[method].update(auc_dic)\n",
    "\n",
    "        print('AUC Results')\n",
    "        pp.pprint(auc_results)\n",
    "        print('')\n",
    "        ###################################################\n",
    "    \n",
    "    if show_total is True and yaxis in ['patk_all']:\n",
    "        noise_rate = tmp_figpath.split('_')[-1].replace('ass', '').replace('uni', '').replace('.png', '')\n",
    "        noise_rate = int(noise_rate)*0.01\n",
    "        ax.axhline(noise_rate, color='r', linestyle='dotted', linewidth=2)\n",
    "        yticks = [*ax.get_yticks()]\n",
    "        yticklabels = [*ax.get_yticklabels()]\n",
    "        ax.set_yticks(yticks, labels=yticklabels)\n",
    "\n",
    "    elif show_total is True and yaxis == 'ratk_all': \n",
    "        intervals = grouped_df[xaxis].unique()\n",
    "        max_items = max([int(i) for i in intervals])\n",
    "        min_items = min([int(i) for i in intervals])\n",
    "\n",
    "        noise_rate = tmp_figpath.split('_')[-1].replace('ass', '').replace('uni', '').replace('.png', '')\n",
    "        noise_rate = int(noise_rate)*0.01\n",
    "        slope=noise_rate\n",
    "        start_y = 0\n",
    "        max_epo = max(df['Epoch'].unique())\n",
    "        num_data_per_method = len(df)/(len(df['Method'].unique())*max_epo)\n",
    "        end_y = (max_items*noise_rate)/ (num_data_per_method/topn*noise_rate)\n",
    "        print(f'start_y={start_y}, slope={slope}')\n",
    "\n",
    "        # this is for xaxis range from 0 to 1\n",
    "        xy1 = (0,start_y)\n",
    "        xy2 = (1,end_y)\n",
    "        print(f'xy1 and xy2={xy1, xy2}')\n",
    "        ax.axline(xy1, xy2, color='r', linestyle='dotted', linewidth=2)\n",
    "\n",
    "        yticks = [*ax.get_yticks()]\n",
    "        yticklabels = [*ax.get_yticklabels()]\n",
    "        ax.set_yticks(yticks, labels=yticklabels)\n",
    "\n",
    "    leg = ax.legend()\n",
    "    for i in leg.legendHandles:\n",
    "        i.set_linewidth(6)\n",
    "\n",
    "    hue = 'Classes'\n",
    "\n",
    "    # Not working\n",
    "    # leg.set_title(hue)\n",
    "    # leg.get_title().set_fontsize('40')\n",
    "\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize=24)\n",
    "    ax.set(xlabel='', ylabel = '')\n",
    "    ax.tick_params(axis='x', labelsize=26)\n",
    "    ax.tick_params(axis='y', labelsize=22)\n",
    "\n",
    "    # Do not use it for thesis\n",
    "    # plt.title(\"Precision of Classes Across Intervals\")\n",
    "    # plt.ylabel(\"Precision\")\n",
    "    # plt.xlabel(\"Interval\")\n",
    "    # plt.legend(title=\"Class\")\n",
    "    ax.get_legend().set_visible(False)\n",
    "    \n",
    "    plt.grid(linewidth = 0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{tmp_figpath}', dpi=80)\n",
    "    plt.show()\n",
    "\n",
    "    return auc_results\n",
    "\n",
    "############################################\n",
    "##################  Per Class  ##################\n",
    "start = time.time()\n",
    "# m_names = ['clean', 'clean_uni20', 'uni20','clean_uni1', 'uni1', 'clean_ass20', 'ass20', 'clean_ass1', 'ass1']\n",
    "# m_names = [ 'uni20',  'ass20',  'uni10',  'ass10']\n",
    "m_names = [ 'uni20',  'ass20',  'uni10',  'ass10', 'uni5',  'ass5', 'uni1',  'ass1']\n",
    "# m_names = ['ass20']\n",
    "# m_names = ['clean', 'clean_uni1', 'uni1', 'clean_ass1', 'ass1']\n",
    "# m_names = ['uni1','ass20','ass1']\n",
    "methods = ['CL_SC',  'SC','CL_NM', 'NM']\n",
    "# methods = ['CL_SC', 'CL_NM']\n",
    "# methods = ['CL_SC', 'SC']\n",
    "# methods = ['CL_NM']\n",
    "\n",
    "topn = None\n",
    "\n",
    "epos = list(range(1, 6))\n",
    "\n",
    "\n",
    "topn = 2000\n",
    "# show_total = False\n",
    "show_total = True\n",
    "# num_intervals = 10\n",
    "cut_by_confident_joint = False\n",
    "# cut_by_confident_joint = True\n",
    "\n",
    "# Default to all\n",
    "classname = 'all'\n",
    "# yaxis = 'Precision'\n",
    "yaxis = 'patk_all'\n",
    "# yaxis = 'ratk_all'\n",
    "# yaxis = 'patk'\n",
    "# yaxis = 'ratk'\n",
    "\n",
    "\n",
    "if yaxis == 'Precision':\n",
    "    topn = 14323\n",
    "    num_intervals = 10\n",
    "    topn = len(df)-len(df) % num_intervals\n",
    "    interval_size = topn // num_intervals\n",
    "\n",
    "auc_dic = {m: {} for m in m_names}\n",
    "\n",
    "for i, m_name in tqdm(enumerate(m_names)):\n",
    "    tmp_df = None\n",
    "\n",
    "    grouped_filedir = f'./postprocessing/code/grouped/{coco_gdino_backbone}'\n",
    "    grouped_filepath = f'{grouped_filedir}/{m_name}_{yaxis}.csv'\n",
    "\n",
    "    if not os.path.isfile(grouped_filepath):\n",
    "        os.makedirs(grouped_filedir, exist_ok=True)\n",
    "\n",
    "    for method in methods:\n",
    "        confident_joint_thresh = None\n",
    "        # confident_joint_threshs = []\n",
    "        for epo in epos:\n",
    "\n",
    "            print(f'Process {m_name} {method} {epo}')\n",
    "            df = m_dic[m_name][epo].copy()\n",
    "            tpfp = topn_dic[m_name][epo][method][classname]\n",
    "\n",
    "            sorted_idxs, df, total_c_incorrect, total_c_correct = get_sorted_idxes_and_c_incorrect(df, classname, method, is_remove=False)\n",
    "\n",
    "            df['aed_tpfp'] = tpfp\n",
    "\n",
    "            # print(f'len(df) ={len(df)}')\n",
    "            print(f'total_c_incorrect={total_c_incorrect}, total_c_correct={total_c_correct}')\n",
    "            assert len(df) == total_c_incorrect + total_c_correct\n",
    "\n",
    "            #######################################\n",
    "            #                 Dynamic interval for the topmax\n",
    "            #######################################\n",
    "            if topn is None:\n",
    "                num_intervals = len(df) #interval = 1\n",
    "                topn = (len(df)-len(df) % num_intervals)\n",
    "                interval_size = topn // num_intervals\n",
    "\n",
    "            # Create a dynamic 'Interval' column\n",
    "            elif yaxis in ['patk', 'ratk', 'patk_all', 'ratk_all'] and cut_by_confident_joint is False:\n",
    "                # Recall at all need all df data\n",
    "                topn = topn\n",
    "                num_intervals = len(df)\n",
    "                interval_size = len(df) // num_intervals\n",
    "            #######################################\n",
    "\n",
    "            #######################################\n",
    "            #                           Set Confident_thresh\n",
    "            #######################################\n",
    "            if yaxis in ['patk', 'ratk', 'patk_all', 'ratk_all']:\n",
    "            # if yaxis in ['patk', 'ratk', 'patk_all', 'ratk_all'] and cut_by_confident_joint is True:\n",
    "                if method[:3] == 'CL_':\n",
    "                    # CL_NM and CL_SC is equal to the number of confident joint\n",
    "                    confident_joint_thresh = len(sorted_idxs)\n",
    "\n",
    "                interval_size = 1\n",
    "\n",
    "                # Do not cut df here since recall need all df to calculate\n",
    "                print(f'Confident confident_joint_thresh={confident_joint_thresh} len(df) ={len(df)}')\n",
    "            \n",
    "\n",
    "            print(f'Final Confident confident_joint_thresh={confident_joint_thresh} for {method}')\n",
    "\n",
    "            df['Interval'] = np.repeat(np.arange(1, num_intervals+1) * interval_size, interval_size)\n",
    "            df['Method'] = method\n",
    "            df['Epoch'] = epo\n",
    "            df['confident_joint_thresh'] =  confident_joint_thresh\n",
    "\n",
    "            if yaxis in ['Precision', 'patk', 'ratk']:\n",
    "                img_prefix = f'{method}_{m_name}'\n",
    "\n",
    "                ######### process_interval_counts_per_class ######### \n",
    "                # figdir = f'./postprocessing/fig/SHIFT_gdino/shift_gdino_interval_precision_true_perclass'\n",
    "                # figdir = f'./postprocessing/fig/SHIFT_gdino/shift_gdino_interval_precision_pred_perclass'\n",
    "                # figpath =f'{figdir}/top{topn}_{img_prefix}.png'\n",
    "                # process_interval_counts_per_class(df, figdir, img_prefix, classname)\n",
    "\n",
    "                ######### process_interval_precision ######### \n",
    "                figdir = f'./postprocessing/fig/{coco_gdino_backbone}/all_perclass_{yaxis}'\n",
    "\n",
    "                if not os.path.isdir(figdir):\n",
    "                    os.makedirs(figdir, exist_ok=True)\n",
    "                    \n",
    "                figpath =f'{figdir}/top{topn}_{img_prefix}.png'\n",
    "                # figpath =f'{figdir}/topmax_{img_prefix}.png'\n",
    "                process_interval_precision(df, figpath, yaxis, topn, show_total=True)\n",
    "\n",
    "            if yaxis in ['patk_all', 'ratk_all']:\n",
    "\n",
    "                if tmp_df is None:\n",
    "                    tmp_df = df.copy()\n",
    "                else:\n",
    "                    if df['Method'].unique() == 'SC':\n",
    "                        df['confident_joint_thresh'] = tmp_df.loc[(tmp_df['Method'] == 'CL_SC')&(tmp_df['Epoch'] == epo)]['confident_joint_thresh'].values\n",
    "\n",
    "                    elif df['Method'].unique() == 'NM':\n",
    "                        df['confident_joint_thresh'] = tmp_df.loc[(tmp_df['Method'] == 'CL_NM')&(tmp_df['Epoch'] == epo)]['confident_joint_thresh'].values\n",
    "\n",
    "\n",
    "                    tmp_df = pd.concat([tmp_df, df], axis=0)\n",
    "\n",
    "    if yaxis in ['patk_all', 'ratk_all']:\n",
    "        if cut_by_confident_joint is True:\n",
    "            figdir = f'./postprocessing/fig/{coco_gdino_backbone}/coco_cj_{yaxis}'\n",
    "        else:\n",
    "            figdir = f'./postprocessing/fig/{coco_gdino_backbone}/coco_{yaxis}'\n",
    "\n",
    "        if not os.path.isdir(figdir):\n",
    "            os.makedirs(figdir, exist_ok=True)\n",
    "        if cut_by_confident_joint is True:\n",
    "            figpath =f'{figdir}/topcj_{m_name}.png'\n",
    "        else:\n",
    "            figpath =f'{figdir}/top{topn}_{m_name}.png'\n",
    "\n",
    "        # Not useful\n",
    "        # if yaxis == 'patk_all':\n",
    "        #     tmp_df = tmp_df.loc[tmp_df['Interval'] <= tmp_df['confident_joint_thresh']]\n",
    "        \n",
    "\n",
    "        auc_result = process_interval_precision(tmp_df, figpath, grouped_filepath, yaxis, topn, cut_by_confident_joint, total_c_incorrect, show_total)\n",
    "\n",
    "        auc_dic.update({m_name: auc_result})\n",
    "        print(f'---------------- end of {m_name} ----------------')\n",
    "\n",
    "\n",
    "\n",
    "auc_dic_path = f'./postprocessing/code/DataFrame/{coco_gdino_backbone}/aed_auc'\n",
    "\n",
    "if not os.path.isdir(auc_dic_path):\n",
    "    os.makedirs(auc_dic_path, exist_ok=True)\n",
    "\n",
    "if topn == 200:\n",
    "    auc_filepath = f'{auc_dic_path}/top200_{yaxis}.pkl'\n",
    "elif topn == 1000:\n",
    "    auc_filepath = f'{auc_dic_path}/top1000_{yaxis}.pkl'\n",
    "elif topn == 2000:\n",
    "    auc_filepath = f'{auc_dic_path}/top2000_{yaxis}.pkl'\n",
    "elif cut_by_confident_joint is True:\n",
    "    auc_filepath = f'{auc_dic_path}/cj_{yaxis}.pkl'\n",
    "\n",
    "# topmax patk is not saved\n",
    "with open (auc_filepath, 'wb') as f:\n",
    "    pickle.dump(auc_dic, f)\n",
    "\n",
    "# auc_ratk_dic\n",
    "\n",
    "end = time.time()\n",
    "duration = end-start\n",
    "time_format = time.strftime(\"%H:%M:%S\", time.gmtime(duration))\n",
    "print(f'duration={time_format}')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saved Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bboxes(img, gt_bboxes, gt_labels, gt_labels_des, pred_labels, pred_labels_des, name2RGB, name2white, isshow, isfont):\n",
    "\n",
    "    for idx, (gt_bbox, gt_label, gt_label_des, pred_label, pred_label_des) in enumerate(zip(gt_bboxes, gt_labels, gt_labels_des, pred_labels, pred_labels_des)):\n",
    "\n",
    "        ymin, xmin, ymax, xmax = [int(i) for i in gt_bbox]\n",
    "        \n",
    "        # start = (xmin, ymin)\n",
    "        # end = (xmax, ymax)\n",
    "        r = [xmin, xmax, xmax, xmin, xmin]\n",
    "        c = [ymax, ymax, ymin, ymin, ymax]\n",
    "        rr, cc = polygon_perimeter(r, c, img.shape)\n",
    "        # rr, cc = polygon_perimeter(start, end=end, shape=img.shape)\n",
    "        rgb = name2RGB[gt_label_des]\n",
    "        img[rr, cc ,0] = rgb[0]\n",
    "        img[rr, cc ,1] = rgb[1]\n",
    "        img[rr, cc ,2] = rgb[2]\n",
    "\n",
    "        if isfont is True:\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            text_org = (ymin, xmin-2)\n",
    "\n",
    "            if gt_label_des == 'traffic sign':\n",
    "                gt_label_des = 'sign'\n",
    "            elif gt_label_des == 'traffic light':\n",
    "                gt_label_des = 'light'\n",
    "\n",
    "            labeltext = f'{gt_label_des}'\n",
    "            cv2.putText(img, labeltext, text_org, font, 0.5, rgb, 1)\n",
    "\n",
    "    # print(f'img.shape={img.shape}')\n",
    "    # img = np.moveaxis(img, 0, -1)\n",
    "    \n",
    "    # dpi = 150\n",
    "    # fig = plt.figure(dpi=dpi, figsize=(12,14))\n",
    "    # plt.imshow(img)\n",
    "    if isshow is True:\n",
    "        dpi = 150\n",
    "        fig = plt.figure(dpi=dpi, figsize=(7,9))\n",
    "        plt.imshow(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def crop_bbox(xmin, ymin, xmax, ymax, img, img_shape, pad=0):\n",
    "    img_xmax = img_shape[0]\n",
    "    img_ymax = img_shape[1]\n",
    "    xmin = int(xmin) - pad if int(xmin) - pad > 0 else 0\n",
    "    ymin = int(ymin) - pad if int(ymin) - pad > 0 else 0\n",
    "    xmax = int(xmax) + pad if int(xmin) + pad > 0 else img_xmax\n",
    "    ymax = int(ymax) + pad if int(ymax) + pad > 0 else img_ymax\n",
    "\n",
    "    # print(f'img.shape={img.shape}')\n",
    "    cropped = img[xmin:xmax, ymin:ymax, :]\n",
    "    # print(f'cropped.shape={cropped.shape}')\n",
    "    return cropped\n",
    "    \n",
    "\n",
    "def crop_bboxes(img, img_shape, gt_bboxes, gt_labels, pad):\n",
    "    bbox_imgs = []\n",
    "\n",
    "    for idx, (bbox, labels) in enumerate(zip(gt_bboxes, gt_labels)):\n",
    "        ymin, xmin, ymax, xmax = bbox\n",
    "        \n",
    "        bbox_img = crop_bbox(xmin, ymin, xmax, ymax, img, img_shape, pad)\n",
    "        bbox_imgs.append(bbox_img)\n",
    "\n",
    "    return bbox_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_names = ['uni20', 'uni10', 'uni5', 'uni1', 'ass20', 'ass10', 'ass5', 'ass1']\n",
    "m_name = 'uni20'\n",
    "\n",
    "\n",
    "################## by class sorted by AED method #################\n",
    "# classname = 'person'\n",
    "# classname = 'bus'\n",
    "# classname = 'motorcycle'\n",
    "classname = 'bicycle'\n",
    "topn = 10\n",
    "method = 'CL_SC'\n",
    "\n",
    "colnames = [\"prob\", \"c_incorrect\", \"true_label_des\", \"label_gt\", \"label_gt_des\", \"label_pred\", \"label_pred_des\", \"imgpath\", \"bbox_gt\",\"prob\", \"CL_SC\", \"SC\", \"loss\", \"CL_NM\", \"NM\", classname]\n",
    "\n",
    "# ascending=True is for AED\n",
    "epo_df = m_dic[m_name]\n",
    "class_df = epo_df.loc[epo_df['label_gt_des']==classname, colnames]\n",
    "class_df.sort_values(by=method, ascending=False, inplace=True)\n",
    "print(class_df['imgpath'].values[:topn])\n",
    "print(class_df.head(topn))\n",
    "\n",
    "################## all sorted by AED method ################# \n",
    "# classname = 'all'\n",
    "topn = 20\n",
    "\n",
    "# colnames = [\"prob\", \"c_incorrect\", \"true_label_des\", \"label_gt\", \"label_gt_des\", \"label_pred\", \"label_pred_des\", \"imgpath\", \"bbox_gt\",\"prob\", \"CL_SC\", \"SC\", \"loss\", \"CL_NM\", \"NM\"]\n",
    "\n",
    "# epo_df = m_dic[m_name]\n",
    "# class_df = epo_df\n",
    "# class_df.sort_values(by=method, ascending=True, inplace=True)\n",
    "# print(class_df['imgpath'].values[:topn])\n",
    "# print(f' ------------- df -------------')\n",
    "# print(class_df.head(topn))\n",
    "##################################################### \n",
    "\n",
    "cnt = 0\n",
    "for bbox_idx, row in class_df.iterrows():\n",
    "    img = np.array(Image.open(row['imgpath']))\n",
    "    img_shape = img.shape\n",
    "\n",
    "    isshow = False\n",
    "    isfont = False\n",
    "    img_with_bbox = draw_bboxes(img, [row['bbox_gt']], [row['label_gt']], [row['label_gt_des']], [row['label_pred']], [row['label_pred_des']], name2red, name2red, isshow, isfont)\n",
    "\n",
    "    bbox_img = crop_bboxes(img_with_bbox, img_shape, [row['bbox_gt']], [row['label_gt']], pad=15)[0]\n",
    "\n",
    "    # # plt.imshow(img_with_bbox, cmap=\"gray\")\n",
    "    plt.imshow(bbox_img, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    fig_dirpath = f'./postprocessing/fig/COCO_gdino_swint/{method}_perclass_{classname}'\n",
    "\n",
    "    if os.path.exists(fig_dirpath) is False:\n",
    "        os.makedirs(fig_dirpath)\n",
    "\n",
    "    imgpath = row['imgpath'].replace(f'{data_dirpath}/coco2017/val2017', '')\n",
    "    imgname = imgpath.replace('.jpg', '').replace('/', '_')\n",
    "\n",
    "    plt.savefig(f\"{fig_dirpath}/{classname}_{cnt}_{imgname}.png\", bbox_inches='tight')\n",
    "    \n",
    "\n",
    "    # print(f'bbox_idx={bbox_idx}, classname={classname}')\n",
    "    cnt += 1\n",
    "\n",
    "    if cnt > topn:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "#     bdd100k_det = {\n",
    "#     0: \"pedestrian\",\n",
    "#     1: \"rider\",\n",
    "#     2: \"car\",\n",
    "#     3: \"truck\",\n",
    "#     4: \"bus\",\n",
    "#     5: \"train\",\n",
    "#     6: \"motorcycle\",\n",
    "#     7: \"bicycle\",\n",
    "#     8: \"traffic light\",\n",
    "#     9: \"traffic sign\",\n",
    "#     10: \"bg\",\n",
    "# }\n",
    "\n",
    "# shift_det = {\n",
    "#     0: \"pedestrian\",\n",
    "#     1: \"car\",\n",
    "#     2: \"truck\",\n",
    "#     3: \"bus\",\n",
    "#     4: \"motorcycle\",\n",
    "#     5: \"bicycle\",\n",
    "#     6: \"bg\"\n",
    "# }\n",
    "\n",
    "# peak_mapper = {\n",
    "#     \"pedestrian\": \"bicycle\",\n",
    "#     \"car\": \"bus\",\n",
    "#     \"truck\": \"car\",\n",
    "#     \"bus\": \"truck\",\n",
    "#     \"motorcycle\": \"bicycle\",\n",
    "#     \"bicycle\": \"motorcycle\",\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# Process uni20_CL_NM\n",
    "# 114429 sorted index IS CORRECT!!!\n",
    "# sorted_idxs=[ 10651  85016  24539 138069 146284  58880 203362 208731  85025 136181\n",
    "#  142707 127501 203396  10685 174450 138192  84967  57632 128911 106806\n",
    "#  191731 205953 111124 185426 203334 191570  10803 113378 123325 191557\n",
    "#   16253  61229 127419 154653 191551 150561 193439 203446 202715 201437\n",
    "#  191577 180237 127185  20805 185663 154610  16480 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate AED Precision Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix, roc_auc_score, precision_score\n",
    "from scipy.special import softmax\n",
    "from collections import Counter\n",
    "\n",
    "is_issue_types = ['c_incorrect', 'c_correct', 'ambiguous', 'bb_incorrect']\n",
    "\n",
    "# All methods\n",
    "# methods = ['PBNR_NMargin','PBNR_SConf','PBNR_CWE','CL_NMargin','CL_SConf','CL_CWE','ArgMax_NMargin','ArgMax_SConf','ArgMax_CWE', 'LRank']\n",
    "# methods = ['CL_NM','CL_SC','CL_CWE',\n",
    "#  'PBC_NM',  'PBC_SC', 'PBC_CWE',\n",
    "#  'PBNR_NM', 'PBNR_SC', 'PBNR_CWE',\n",
    "# 'BO_NM', 'BO_SC', 'BO_CWE',\n",
    "# 'PNG_NM', 'PNG_SC', 'PNG_CWE',\n",
    "#  'LRank']\n",
    "methods = ['LRank','CL_SC', 'NM', 'CL_NM']\n",
    "m_names = ['clean', 'uni20', 'uni10', 'uni5', 'uni1', 'ass20', 'ass10', 'ass5', 'ass1']\n",
    "# m_names = ['uni20', 'uni10', 'uni5', 'uni1', 'ass20', 'ass10', 'ass5', 'ass1']\n",
    "# m_names = ['uni1', 'ass1']\n",
    "\n",
    "# TNR is specificity\n",
    "colnames = ['Method', 'Class',\n",
    "            'TP_all', 'FP_all','Precision', 'Recall',\n",
    "            'TP10', 'FP10', 'P@10',\n",
    "            'TP100', 'FP100', 'P@100',\n",
    "            'TP1000', 'FP1000', 'P@1000',\n",
    "            ]\n",
    "\n",
    "df_cal = pd.DataFrame(columns=colnames)\n",
    "\n",
    "\n",
    "\n",
    "def cm_by_topn(epo_df, default_df, detected_idxs, is_ambi, by_classes):\n",
    "\n",
    "    # is_ambi is useless for SHIFT\n",
    "    if is_ambi is True:\n",
    "        conditions = (default_df['c_incorrect'] == 'TRUE') | (default_df['ambiguous'] == 'TRUE') | (default_df['c_incorrect'] == 'TRUE')\n",
    "    else:\n",
    "        conditions = (default_df['c_incorrect'] == True)\n",
    "\n",
    "    assert len(epo_df) == len(default_df), 'len of epo_df and default_df are not equal'\n",
    "\n",
    "    total_idxs = default_df.index.to_numpy()\n",
    "    assert np.array_equal(epo_df.index.to_numpy(), total_idxs), 'index of epo_df and default_df are not equal'\n",
    "\n",
    "    # relevant items = TP + FN\n",
    "    # This is y_true, based on the error conditions (E and EA)\n",
    "    relevant_idxs = default_df.loc[conditions, :].index.tolist()\n",
    "\n",
    "    # Only top N\n",
    "    y_true = [True if idx in relevant_idxs else False for idx in total_idxs]\n",
    "\n",
    "    # retrieved items = TP + FP\n",
    "    # This is y_pred\n",
    "    retrived_idxs = default_df.loc[detected_idxs, :].index.tolist()\n",
    "    y_pred = [True if idx in retrived_idxs else False for idx in total_idxs]\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[True, False])\n",
    "    precision = 100.0 * precision_score(y_true, y_pred, labels=[True, False], zero_division=0.0)\n",
    "\n",
    "    # tn, fp, fn, tp = cm.ravel()\n",
    "    # tp, fn, fp,tn = cm.ravel()\n",
    "\n",
    "    \n",
    "    return cm, precision\n",
    "\n",
    "\n",
    "def gen_cal_df(m_names, by_classes=False):\n",
    "    \n",
    "    cal_dic = {m: None for m in m_names}\n",
    "\n",
    "    for m_name in m_names:\n",
    "\n",
    "        print(f'-----------------Model {m_name} -----------------')\n",
    "        epo_df = m_dic[m_name]\n",
    "        df_cal = pd.DataFrame(columns=colnames)\n",
    "\n",
    "        for method in methods:\n",
    "\n",
    "            top_percentage = 1.0\n",
    "            if by_classes is False:\n",
    "\n",
    "                # This is default\n",
    "                classname = 'all'\n",
    "\n",
    "                ########################################################\n",
    "                #               Number of Detected data                #\n",
    "                ########################################################\n",
    "                if method == 'LRank':\n",
    "\n",
    "                    topn_thresh = int(round(len(epo_df.loc[epo_df['CL_SC'] != 999999]) * top_percentage))\n",
    "\n",
    "                    # print(f'topNthresh={topNthresh} for LRank')\n",
    "                    lossrank_df = epo_df.sort_values(by='loss', ascending=False)\n",
    "                    detected_df = lossrank_df[:topn_thresh]\n",
    "                    # detected_df = epo_df.loc[epo_df[method] <= topNthresh]\n",
    "\n",
    "                elif method  in ['NM', 'SC', 'RC', 'E']:\n",
    "                    cl_idxs = epo_df.loc[epo_df['CL_SC'] != 999999].index.values\n",
    "\n",
    "                    detected_df = epo_df.loc[cl_idxs].sort_values(by=method, ascending=True)\n",
    "\n",
    "                elif method  in ['REN']:\n",
    "                    cl_idxs = epo_df.loc[epo_df['CL_SC'] != 999999].index.values\n",
    "\n",
    "                    # For entropy and relative entropy\n",
    "                    # higher the better\n",
    "                    detected_df = epo_df.loc[cl_idxs].sort_values(by=method, ascending=False)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    detected_df = epo_df.loc[epo_df[method] != 999999].sort_values(by=method, ascending=True)\n",
    "                    # topn = int(round(len(detected_df) * top_percentage))\n",
    "                    # detected_df = detected_df[:topn]\n",
    "\n",
    "\n",
    "                ########################################################\n",
    "                #               Number of Detected data                #\n",
    "                ########################################################\n",
    "                detected_idxs = detected_df.index.tolist()\n",
    "\n",
    "\n",
    "    \n",
    "                #######################################################\n",
    "                #                  Precision at K                     #\n",
    "                #######################################################\n",
    "\n",
    "                cm_all, precision_all = cm_by_topn(epo_df, epo_df, detected_idxs, is_ambi=False, by_classes=by_classes)\n",
    "                tp, fn, fp,tn = cm_all.ravel()\n",
    "                recall_all = 0\n",
    "                if (tp + fn) > 0:\n",
    "                    recall_all = 100.0 * tp / (tp + fn)\n",
    "\n",
    "\n",
    "                topn = 10\n",
    "                top10_idxs = detected_df[:topn].index.tolist()\n",
    "                cm10, p10 = cm_by_topn(detected_df[:topn], detected_df[:topn], top10_idxs, is_ambi=False, by_classes=by_classes)\n",
    "                tp10, fn10, fp10,tn10 = cm10.ravel()\n",
    "\n",
    "                topn = 100\n",
    "                top100_idxs = detected_df[:topn].index.tolist()\n",
    "                cm100, p100 = cm_by_topn(detected_df[:topn], detected_df[:topn], top100_idxs, is_ambi=False, by_classes=by_classes)\n",
    "                tp100, fn100, fp100,tn100 = cm100.ravel()\n",
    "\n",
    "                topn = 1000\n",
    "                top1000_idxs = detected_df[:topn].index.tolist()\n",
    "                cm1000, p1000 = cm_by_topn(detected_df[:topn], detected_df[:topn], top1000_idxs, is_ambi=False, by_classes=by_classes)\n",
    "                tp1000, fn1000, fp1000,tn1000 = cm1000.ravel()\n",
    "\n",
    "                row = [method, classname,\n",
    "                    tp, fp, precision_all, recall_all,\n",
    "                    tp10, fp10, p10,\n",
    "                    tp100, fp100, p100,\n",
    "                    tp1000, fp1000, p1000\n",
    "                    ]\n",
    "\n",
    "                df_cal = pd.concat([df_cal, pd.DataFrame([row], columns=colnames)], ignore_index=True)\n",
    "\n",
    "\n",
    "            else: # else here\n",
    "                ##################################\n",
    "                #                        Number of Detected data                  #\n",
    "                ##################################\n",
    "                # filter by class first\n",
    "                classnames = [i for i in id2class.values()]\n",
    "\n",
    "                for _, classname in enumerate(classnames):\n",
    "\n",
    "                    class_df = epo_df.loc[epo_df['label_gt_des']==classname, :]\n",
    "\n",
    "                    if method == 'LRank':\n",
    "\n",
    "                        # topn_thresh = int(round(len(epo_df.loc[epo_df['CL_SConf'] != 999999]) * top_percentage))\n",
    "\n",
    "                        # print(f'topNthresh={topNthresh} for LRank')\n",
    "                        detected_df = class_df.sort_values(by='loss', ascending=False)\n",
    "                        # detected_df = lossrank_df[:topn_thresh]\n",
    "\n",
    "                    elif method  in ['NM', 'SC', 'RC', 'EN']:\n",
    "                        cl_idxs = class_df.loc[class_df['CL_SC'] != 999999].index.values\n",
    "\n",
    "                        detected_df = class_df.loc[cl_idxs].sort_values(by=method, ascending=True)\n",
    "\n",
    "                    elif method  in ['REN']:\n",
    "                        cl_idxs = class_df.loc[class_df['CL_SC'] != 999999].index.values\n",
    "\n",
    "                        detected_df = class_df.loc[cl_idxs].sort_values(by=method, ascending=False)\n",
    "\n",
    "                    else: #where\n",
    "\n",
    "                        detected_df = class_df.loc[class_df[method] != 999999].sort_values(by=method, ascending=True)\n",
    "                        # topn = int(round(len(detected_df) * top_percentage))\n",
    "                        # detected_df = detected_df[:topn]\n",
    "\n",
    "                    ########################################################\n",
    "                    #               Number of Detected data                #\n",
    "                    ########################################################\n",
    "                    detected_idxs = detected_df.index.tolist()\n",
    "\n",
    "                    # DEBUG\n",
    "                    # if classname == 'bicycle' and method == 'CL_SConf':\n",
    "                    #     print('here')\n",
    "                    # else:\n",
    "                    #     continue\n",
    "\n",
    "                    \n",
    "                    #######################################################\n",
    "                    #                  Precision at K                     #\n",
    "                    #######################################################\n",
    "                    # Can't  use class_df here, cause it only contains relevant elements(FN+TP)!\n",
    "                    cm_all, precision_all = cm_by_topn(detected_df, detected_df, detected_idxs, is_ambi=False, by_classes=by_classes)\n",
    "                    tp,fn,fp,tn = cm_all.ravel()\n",
    "\n",
    "                    recall_all = 0\n",
    "                    if (tp + fn) > 0:\n",
    "                        recall_all = 100.0 * tp / (tp + fn)\n",
    "\n",
    "\n",
    "                    topn = 10\n",
    "                    top10_idxs = detected_df[:topn].index.tolist()\n",
    "                    cm10, p10 = cm_by_topn(detected_df[:topn], detected_df[:topn], top10_idxs, is_ambi=False, by_classes=by_classes)\n",
    "                    tp10, fn10, fp10,tn10 = cm10.ravel()\n",
    "                    # recall10 = 100.0 * tp10 / (tp10 + fn10)\n",
    "\n",
    "                    topn = 100\n",
    "                    top100_idxs = detected_df[:topn].index.tolist()\n",
    "                    cm100, p100 = cm_by_topn(detected_df[:topn], detected_df[:topn], top100_idxs, is_ambi=False, by_classes=by_classes)\n",
    "                    tp100, fn100, fp100,tn100 = cm100.ravel()\n",
    "\n",
    "                    topn = 1000\n",
    "                    top1000_idxs = detected_df[:topn].index.tolist()\n",
    "                    cm1000, p1000 = cm_by_topn(detected_df[:topn], detected_df[:topn], top1000_idxs, is_ambi=False, by_classes=by_classes)\n",
    "                    tp1000, fn1000, fp1000,tn1000 = cm1000.ravel()\n",
    "\n",
    "                    row = [method, classname,\n",
    "                        tp, fp, precision_all, recall_all,\n",
    "                        tp10, fp10, p10,\n",
    "                        tp100, fp100, p100,\n",
    "                        tp1000, fp1000, p1000\n",
    "                        ]\n",
    "\n",
    "                    df_cal = pd.concat([df_cal, pd.DataFrame([row], columns=colnames)], ignore_index=True)\n",
    "                \n",
    "            cal_dic[m_name] = df_cal\n",
    "\n",
    "        print(f'-----------------End of m_name {m_name}-----------------')\n",
    "\n",
    "    return cal_dic\n",
    "\n",
    "\n",
    "cal_dic = gen_cal_df(m_names, by_classes=False)\n",
    "cal_byclass_dic = gen_cal_df(m_names, by_classes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mname = 'uni1'\n",
    "# # cal_dic[test_mname]\n",
    "# topn_byclass_dic[test_mname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_df = aed_perf['all'][test_mname].copy()\n",
    "tmp_df = aed_perf['byclass'][test_mname].copy()\n",
    "conds = (tmp_df['Method']=='CL_NM')\n",
    "tmp_df.loc[conds, :]\n",
    "# tmp_df\n",
    "\n",
    "# for row, row_new in zip(tmp_df.loc[conds, :].iterrows(), cal_byclass_dic['uni1']):\n",
    "#     if row[1]['Class'] = row_new[1]['Class']\n",
    "#     print(row[1]['Class'], row[1]['Precision'], row[1]['Recall'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "vscode": {
   "interpreter": {
    "hash": "a6f83e59ecc3e011402656f1ade4da194b5ea4c9c1c11f252553be49d4f31024"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
